<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker配置TLS认证开启远程访问]]></title>
    <url>%2Fposts%2Fdocker%E9%85%8D%E7%BD%AETLS%E8%AE%A4%E8%AF%81%E5%BC%80%E5%90%AF%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[前言 docker在今天对应用开发，运维管理来说已经是必备组件了，web应用的部署，微服务搭建，CI/CD，集群管理哪都有它。关于docker使用这里就不细说了，参考 官方文档。 当我们有多台服务器，每台服务器有多个docker容器，统一管理与监控docker集群就变得非常重要。轻量级的开源docker管理工具有 portainer，重量级的有 rancher。如果服务不多，集群节点不多的话一般 portainer 足以胜任。如果是大型集群的话可以考虑 rancher。 想要中心化的管理docker容器，那么就需要docker容器开启远程访问。在讲怎么开启远程访问之前，要先稍微讲一下 docker容器进程 和 docker守护进程： docker容器进程 顾名思义，就是运行在docker容器中的应用进程，比如你用docker启动的web应用，数据库等 docker守护进程 docker的设计是 C/S模式，docker守护进程（server/服务端）运行在宿主机上，就是你运行docker容器的服务器。当你装完docker并敲下 service docker start时，docker守护进程就启动了，它默认监听 /var/run.docker.sock（unix域套接字）文件, 你可以通过 docker命令（client/客户端）来对容器进行一系列操作，因为 本机 的 docker客户端 是默认通过 /var/run.docker.sock来与 docker守护进程 进行通信的 稍微明白了 docker容器进程 与 docker守护进程 后，你会发现，只有通过docker守护进程，才能与docker容器进行交互。而docker守护进程默认只监听本地的 /va/run/docker.sock，因此只能在本地通过 docker命令操作容器。 能让远程docker客户端访问容器，我们就要让docker守护进程能监听远程访问的端口。docker是采用 socket 进行server和client的连接的，它提供了 tcp和 fd两种方式，一般采用 tcp方式。 配置远程访问 不安全的配置 直接通过 dockerd命令配置守护进程： 12 # 默认监听 6379 端口&gt; $ dockerd -H 0.0.0.0 这样所有ip都能通过 docker -H &lt;remote-dcoker-server_ip&gt;:6379 [OPTION]命令与远程的docker守护进程通信，操作docker容器，生产上不提倡这种做法。 安全的配置 通过 TLS（Transport Layer Security - 安全传输层协议） 来进行远程访问（ 百度百科 - TLS）。我们需要在远程docker服务器（运行docker守护进程的服务器）生成 CA证书，服务器证书，服务器密钥，然后自签名，再颁发给需要连接远程docker容器的服务器。下面是具体操作： 以下操作在 ubuntu 16.04 server上测试成功，其他系统自行参考 修改 openssl配置的CA部分 ubuntu 16.04 下 openssl 配置文件位置： /usr/lib/ssl/openssl.cnf，其他系统可参考 修改如下部分： 123 [ CA_default ]dir = &lt;填你的路径&gt; # 下面的操作以 /etc/openssl 为例 创建相应文件和文件夹： 1234 &gt; $ cd /etc/openssl # 没有就新建&gt; $ mkdir -p &#123;certs,private,tls,crl,newcerts&#125;&gt; $ echo 00 &gt; serial # 注意serial要有数字，不然会报错&gt; $ touch index.txt 生成私钥并自签证书 12 &gt; $ openssl genrsa -out private/cakey.pem -des 1024 # 生成私钥&gt; $ openssl req -new -x509 -key private/cakey.pem -days 3650 -out cacert.pem # 自签证书: 执行后会让你填写一些配置 颁发证书 生成要颁发证书的密钥文件 1 &gt; $ openssl genrsa -out private/test.key 1024 生成证书请求 1 &gt; $ openssl req -new -key private/test.key -days 3650 -out test.csr 颁发证书 1 &gt; $ openssl ca -in test.csr -out certs/test.crt -days 3650 # 这里也需要填写一些配置，最好和前面自签证书的配置保持一致 配置docker守护进程使用TLS认证并监听tcp端口 1234567 &gt; $ service docker stop # 需先停止 docker 服务&gt; $ dockerd --tls \&gt; --tlscacert /etc/openssl/cacert.pem \&gt; --tlscert /etc/openssl/certs/test.crt \&gt; --tlskey /etc/openssl/private/test.key \&gt; -H 0.0.0.0:2375 # 默认 6379 端口，可自定义&gt; $ service docker start # 重启 docker 服务 保存CA证书，服务器证书，服务器密钥 重启docker后，你会发现在远程docker服务器上使用 docker命令不起作用了，这是因为docker守护进程不再监听 var/run/docker.sock文件，而是监听tcp端口了。所以如果要在远程docker服务器使用 docker命令就要加上上面的参数 --tls， --tlscacert， --tlscert， --tlskey，例如： 12345 &gt; $ docker --tls \&gt; --tlscacert /etc/openssl/cacert.pem \&gt; --tlscert /etc/openssl/certs/test.crt \&gt; --tlskey /etc/openssl/private/test.key \&gt; -H $HOSTNAME:2375 ps 这样就太麻烦了，所以我们用下面的做法，将证书，密钥保存到 ~/.docker文件夹，再配置环境变量： 1234567 &gt; $ cd ~/.docker # 没有就新建&gt; $ cp /etc/openssl/cacert.pem ./ca.pem&gt; $ cp /etc/openssl/newcerts/00.pem ./cert.pem&gt; $ cp /etc/openssl/private/test.key ./key.pem&gt; $ echo "export DOCKER_HOST=tcp://$HOSTNAME:2375" &gt;&gt; /etc/profile&gt; $ echo "export DOCKER_TLS_VERIFY=1" &gt;&gt; /etc/profile&gt; $ source /etc/profile 这时你再使用 docker命令就没问题了。 配置portainer添加远程docker集群 添加节点 配置节点属性 需要上传的文件对应为（以下目录在远程docker服务器上） TLS CA certificate: ~/.docker/ca.pem TLS certificate: ~/.docker/cert.pem TLS key: ~/.docker/key.pem 点击 Add endpoint，完成添加。 关于怎么安装 portainer，这里就不介绍了，详细内容参考 官方文档]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>portainer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Ubuntu 18.04 LTS之后的N件事]]></title>
    <url>%2Fposts%2F%E5%AE%89%E8%A3%85Ubuntu-18-04-LTS%E4%B9%8B%E5%90%8E%E7%9A%84N%E4%BB%B6%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[这两天装机，记录下装完系统后的一些后续事项 软件和更新 显卡驱动换成官方的之后可以重启一下，执行下面的命令看看是否安装成功: 1 nvidia-smi 1 ubuntu-drivers devices 设置sudo无密码 执行: 1 sudo visudo 找到 1 %sudo ALL=(ALL:ALL) ALL 改成 1 %sudo ALL=(ALL:ALL) NOPASSWD:ALL 安装neofetch 添加 PPA: 1 sudo add-apt-repository ppa:dawidd0811/neofetch 更新 apt软件列表索引，并下载 neofetch: 1 sudo apt update &amp;&amp; sudo apt install neofetch 执行: 1 neofetch 安装gnome-tweak 执行: 1 sudo apt install gnome-tweak-tool 装完后 程序中文名 叫 优化 安装Opera浏览器（针对博主本人，本人常用浏览器） 去官网下 deb包安装 安装主题和图标 ubuntu 18.04 将桌面环境换成了 Gnome，所以我们的主题是基于 Gnome/Gtk 的 上 这里挑一款自己喜欢的主题: 下面介绍3种安装主题和图标的方法 通过apt安装 这种方法需要所下载的主题或图标 有加入官方PPA源 或者 有提供第三方PPA源 下面以 macOS High Sierra这款主题为例说明: 看到它标题下方的 github地址: https://github.com/vinceliuice/Sierra-gtk-theme: 根据 README进行安装: Ubuntu PPA (maintained by @igor-dyatlov): 1234 sudo add-apt-repository ppa:dyatlov-igor/sierra-themesudo apt updatesudo apt install sierra-gtk-theme # point releasessudo apt install sierra-gtk-theme-git # git master branch 通过ocs-url-tools安装 我们可以看到，每个主题页面右边都有提供 Download和 Install，但是点完 Install却发现浏览器会弹出询问 如何处理ocs: 链接，但是你点了执行却什么都没发生。这是因为你还需要安装 能处理ocs链接的工具 首先，访问 这里，下载 ocs-url_3.0.3-0ubuntu1_amd64.deb（你可以直接点这个链接下载），双击运行安装 回到下载主题的地方，以 Arrongin themes这款主题为例: 直接点 Install安装，选择某个系列（如: Telinkrin-Buttons-Right.tar.xz），浏览器会弹出提示，选择 启动应用程序，弹出如下提示框，点 ok安装: 装完之后点击 open就是打开安装位置，一般在 ~/.theme下；点击 close就是关闭窗口 通过下载压缩包解压安装 安装主题或图标实质上只是把 主题文件 或 图标文件 解压到制定文件夹下，因此我们只要下载某款主题或图标的压缩文件，然后分别解压到下面的位置: 主题文件夹: ~/.theme/ 图标文件夹: ~/.local/share/icons/ 安装gnome-extension ubuntu 18.04 将gnome-shell-theme变成了一个gnome-extension插件，导致gnome-tweak不能直接换shell的主题，因此我们要先安装gnome-extension，下面说明详细步骤 先本地安装支持下载gnome-extension的模块: 1 sudo apt install chrome-gnome-shell 访问 gnome插件商店，点开 User theme插件页面，点击 Click here to install browser extension安装浏览器端的插件下载模块 刷新一下页面，你就能看到右方有个开关按钮，点开就能自动安装插件了。关闭就是禁用插件 现在你不仅可以下载gnome-shell-theme插件，还能下载安装商店里的很多插件了 安装输入法 执行如下命令安装fcitx和googlepinyin: 1 sudo apt install fcitx fcitx-googlepinyin im-config 执行: 1 im-config 指定fcitx的配置即可 安装git/zsh/oh-my-zsh 安装 git: 1 sudo apt install git 顺便配置ssh: 12 cd ~/.sshssh-keygen -C "$&#123;你的git仓库(如github)的email&#125;" 安装 zsh: 1 sudo apt install zsh 安装 oh-my-zsh: 12345 # wgetsh -c "$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)"# curlsh -c "$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" 安装pip pip2: 1234567 # 安装pip2sudo apt updatesudo apt install python-pip# 查看版本pip --verion# 输出: pip 9.0.1 from /usr/lib/python2.7/dist-packages (python 2.7) pip3: 1234567 # 安装pip3sudo apt updatesudo apt install python3-pip# 查看版本pip3 --verion# 输出: pip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6) 安装vim/tmux vim: 1 sudo apt install vim tmux 1 sudo apt install tmux 安装powerline终端美化和字体库 安装 先安装 powerline插件: 1 pip install --user powerline-status 这是一个Python的模块，安装位置一般在 ~/.local/lib/python2.7/site-packages 装完之后，将 ~/.local/bin下的 powerline相关的可执行脚本复制到 ~/.local/lib/python2.7/site-packages/scripts下: 12345 # 先新建scripts文件夹mkdir ~/.local/lib/python2.7/site-packages/scripts# 拷贝脚本到scripts下cp ~/.local/bin/powerline* ~/.local/lib/python2.7/site-packages/scripts 再安装 powerline字体 12345678910 # clonegit clone https://github.com/powerline/fonts.git --depth=1# installcd fonts./install.sh# clean-up a bitcd ..rm -rf fonts 使用 再下面的文件添加对应配置 ~/.zshrc: 12 # 开头添加. /home/$&#123;填你的用户名&#125;/.local/lib/python2.7/site-packages/powerline/bindings/zsh/powerline.zsh ~/.vimrc: 123456 set shell=/bin/zshset rtp+=/home/$&#123;填你的用户名&#125;/.local/lib/python2.7/site-packages/powerline/bindings/vimset guifont=Source\ Code\ Pro\ for\ Powerline:h14set t_Co=256let g:Powerline_symbols = 'fancy'set fillchars+=stl:\ ,stlnc:\ ~/.tmux.conf: 1 source "/home/$&#123;填你的用户名&#125;/.local/lib/python2.7/site-packages/powerline/bindings/tmux/powerline.conf" 安装dotfile（本人的配置文件，针对博主本人，有兴趣可以参考） 12345678910 # clonegit clone git@github.com:tankeryang/dotfile.git# 切换分支git checkout -b ubuntu-18.04 origin/ubuntu-18.04# 复制配置文件cd dotfilecp .zshrc .vimrc .tmux.conf ~/cp .ssh/config ~/.ssh/ 安装ShadowSocks-Qt5/SwitchyOmega 访问 这里下载 release 版本的 ShadowSocks-Qt5可执行程序 Shadowsocks-Qt5-3.0.1-x86_64.AppImage，或者直接 wget下载: 1 wget https://github.com/shadowsocks/shadowsocks-qt5/releases/download/v3.0.1/Shadowsocks-Qt5-3.0.1-x86_64.AppImage 顺便搞一张 icon图标: 1 wget https://avatars1.githubusercontent.com/u/3006190?s=200&amp;v=4 shadowsocks.png 将下载的可执行程序 提权，与图标一起拷贝到 /opt/ShadowSocks-Qt5: 1234567 # 提权chmod a+x $&#123;你的下载路径&#125;/Shadowsocks-Qt5-3.0.1-x86_64.AppImage# 将可执行程序放到/opt/ShadowSocks-Qt5sudo mkdir /opt/ShadowSocks-Qt5mv $&#123;你的下载路径&#125;/Shadowsocks-Qt5-3.0.1-x86_64.AppImage /opt/ShadowSocks-Qt5mv $&#123;你的下载路径&#125;/shaodwsocks.png /opt/ShadowSocks-Qt5 建立启动器 12345 # 进入启动器文件夹cd /usr/share/applications# 新建desktop文件sudo vim ShadowSocks.desktop 写入如下内容 123456789 [Desktop Entry]Name=ShadowSocksComment=ShadowSocksType=ApplicationExec=/opt/ShadowSocks-Qt5/Shadowsocks-Qt5-3.0.1-x86_64.AppImageIcon=/opt/ShadowSocks-Qt5/shadowsocks.pngTerminal=falseStartupNotify=trueCategories=Application; 保存退出，你应该在应用程序里能见到Shadowsocks的启动器图标了 然后安装浏览器代理插件 SwitchyOmega: 点击下载 crx文件: SwitchyOmega.crx，然后将其拖到浏览器中安装 用 wget下载: 1 wget https://github.com/FelisCatus/SwitchyOmega/releases/download/v2.5.15/SwitchyOmega.crx 然后拖到浏览器安装 接下来配置 SwitchyOmega，参考 这篇博客 安装Shutter截图软件 添加源，并安装 shutter: 123 sudo add-apt-repository ppa:shutter/ppasudo apt-get updatesudo apt-get install shutter 设置快捷键 安装微信 访问 这里下载 release 64位版本的 linux-x64.tar.gz，或者用 wget: 1 wget https://github.com/geeeeeeeeek/electronic-wechat/releases/download/V2.0/linux-x64.tar.gz 下载完后解压至 /opt文件夹下: 1 sudo tar -xzvf $&#123;你的下载路径&#125;/linux-x64.tar.gz -C /opt 顺便搞一张 图标: 1 wget -O wechat.png https://images2018.cnblogs.com/blog/1127869/201806/1127869-20180602105354254-1327395543.png 将图标文件放到刚刚解压的路径: 1 sudo mv $&#123;你的下载路径&#125;/wechat.png /opt/electronic-wechat-linux-x64/resources 建立启动器: 12345 # 进入启动器文件夹cd /usr/share/applications# 新建desktop文件sudo vim wechat.desktop 填入以下内容: 123456789 [Desktop Entry]Name=wechatComment=wechatType=ApplicationExec=/opt/electronic-wechat-linux-x64/electronic-wechatIcon=/opt/electronic-wechat-linux-x64/resources/wechat.pngTerminal=falseStartupNotify=trueCategories=Application; 赶快去试试吧～ 安装VSCode 官网下载 deb包安装 安装后将 dotfile里的 vscode配置copy到相应位置（针对博主本人，有兴趣可以参考）: 1 cp ~/dotfile/.vscode/* ~/.config/Code/User/ 安装java 添加源，更新: 12 sudo add-apt-repository ppa:webupd8team/javasudo apt update 安装: 12345 # java8sudo apt install oracle-java8-set-default#java9sudo apt install oracle-java9-set-default 管理java/javac: 12345 # javasudo update-alternatives --config java# javacsudo update-alternatives --config javac 输出，自行选择版本: 12345678 有 1 个候选项可用于替换 java (提供 /usr/bin/java)。选择 路径 优先级 状态------------------------------------------------------------ 0 /usr/lib/jvm/java-8-oracle/jre/bin/java 1081 自动模式* 1 /usr/lib/jvm/java-8-oracle/jre/bin/java 1081 手动模式要维持当前值[*]请按&lt;回车键&gt;，或者键入选择的编号： 12345678 有 1 个候选项可用于替换 javac (提供 /usr/bin/javac)。 选择 路径 优先级 状态------------------------------------------------------------ 0 /usr/lib/jvm/java-8-oracle/bin/javac 1081 自动模式* 1 /usr/lib/jvm/java-8-oracle/bin/javac 1081 手动模式要维持当前值[*]请按&lt;回车键&gt;，或者键入选择的编号： 配置 JAVA_HOME: 1 sudo vim /etc/environment 填入: 1 JAVA_HOME="/usr/lib/jvm/java-8-oracle/jre/bin/java" 使其生效: 1 source /etc/environment 检查是否生效: 1 echo $JAVA_HOME 安装Anaconda 访问 这里，下载你想要的anaconda版本，或者直接 wget: 12 # Anaconda3-5.2.0-Linux-x86_64.shwget https://mirrors4.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.sh 然后执行脚本安装，安装位置推荐放在 /opt或 /usr/local下，注意不要添加环境变量，以免与系统python冲突 安装完后将 anaconda/bin下的可执行程序软连接到 /usr/local/bin下，比如: 12345678 # condasudo ln -s /opt/anaconda3/bin/conda /usr/local/bin/conda# pythonsudo ln -s /opt/anaconda3/bin/python /usr/local/bin/python36 # 命名python36是为了不与系统python冲突# jupytersudo ln -s /opt/anaconda3/bin/jupyter /usr/local/bin/jupyter 终端执行一下 conda， python36， jupyter，看有没有问题 安装JetBrain系列 官网下载 deb包安装]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[半次元爬虫 banciyuan-downloader v2.0 更新]]></title>
    <url>%2Fposts%2F%E5%8D%8A%E6%AC%A1%E5%85%83%E7%88%AC%E8%99%AB-banciyuan-downloader-v2-0-%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[这段时间 半次元前端做了很大的改动，先后更新了两版，之前的小版本 v1.1也不能用了，索性更新了 banciyuan-downloader v2.0版本，做了很大的改变，代码全部封装到 Downloader类里，下面是更新内容 banciyuan-downloader v2.0 更新时间: 2018-06-18 更新原因 半次元前端改版，需要重写脚本以适应HTML解析 半次元登录认证改为通过cookie表单传递认证，需重写登录方法 脚本太乱，需进行封装 更新内容 模块化 将方法封装到类 Downloader里，优化接口方法，可提供外部调用 实现功能 根据 coser_id批量下载某个coser发布的作品的所有图片 图片保存在以 coser名 命名的文件夹内 图片按 coser发布的作品 分文件夹保存，文件夹命名以 作品标签 拼接而成 若有相同标题的作品，则命名文件夹时会加上 顺序编号后缀 防止文件名冲突 图片命名格式为 %num%.jpg/ %num%.png，其中 %num%为从 1开始的 编号 支持智能下载 本地没有的作品，本地已有的作品 不会 重复下载 支持 断点续传 （从断连作品的下一个作品开始下载，若断连作品没下载完，则会丢失一部分断连作品的图片，其余均不影响） 支持超时自动重试 支持下载指定作品 根据频繁I/O进行 多线程优化 不支持无半次元账号的下载，因为有 只有粉丝可见 的限制，最好注册一个半次元账号 只有粉丝可见的作品需关注该coser后方可下载 暂时不支持只下载 COS类的作品，因为半次元改版后没有对 COS和 绘画之类的做分类，都在同一 url下 依赖的库 我的测试环境: python 3.6.4 beautifulsoup 4.5.3 requests 2.13.0 lxml 3.7.2 如何使用 直接运行 run.py 先执行: 1 python run.py 后续步骤参考 v1.0的Usage 自定义实现 因为进行了 模块化，所以可以自行实例化一个 Downloader对象来调用方法实现功能，下面给出简单例子: 分部执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 from bcy_downloader import Downloader# 实例化Downloader对象# 用户名: test# 密码: 123# coser_id: 770554# 下载目录: E:/banciyuandl = Downloader(account='test', password='123', coser_id='770554', bcy_home_dir='E:/banciyuan')# 获取作品url列表dl.get_post_url_list()# 或者自定义下载作品列表dl.post_url_list = ["https://bcy.net/item/detail/6558754255610577155", "https://bcy.net/item/detail/6554677621064466692"]# 查看作品url列表print(dl.post_url_list)# 查看本地已下载作品url列表print(dl.local_post_url_list)# 获取每个作品下所有图片url，得到download_datadl.get_pics_url_list()# 查看download_data# 格式如下# &#123;# '$(post_url)':# &#123;# 'post_name': $(post_name),# 'pics_url_list': $(pics_url_list)# &#125;# &#125;# 例子:# &#123;# "https://bcy.net/item/detail/6558754255610577155":# &#123;# 'post_name': "碧蓝航线-COS-舰娘-场照-返图-cp22-三三笠",# 'pics_url_list': [# 'https://img5.bcyimg.com/user/770554/item/c0je3/63y6vuq8hhgfmge7nrqcaqkpspyfszj5.jpg?1',# 'https://img9.bcyimg.com/user/770554/item/c0je3/esdrtvchzzkfzm74ezd8idx04ennjjfr.jpg?2',# ......# 'https://img9.bcyimg.com/user/770554/item/c0je3/zfiyptpdcpasyz0itzh7ndtmpiysw8uy.jpg?9'# ]# &#125;# &#125;print(dl.download_data)# 根据download_data获取图片dl.get_pics() 一键执行 1234567891011 from bcy_downloader import Downloader# 实例化Downloader对象# 用户名: test# 密码: 123# coser_id: 770554# 下载目录: E:/banciyuandl = Downloader(account='test', password='123', coser_id='770554', bcy_home_dir='E:/banciyuan')# 自动下载dl.run() 注意 v2.0版本下载时会在 每个作品对应的文件夹 里建一个 url.local文件，里面写入的是该作品对应的 url。该文件主要用于 判断本地是否已经下载过该 url对应的作品，以实现智能无重复下载，请不要随意删除 FAQ 有何疑问可在 github发布 issue ，本人会尽量及时查看]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>二次元</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python模块fabric踩坑记录]]></title>
    <url>%2Fposts%2Fpython%E6%A8%A1%E5%9D%97fabric%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[最近都在狂写脚本，好像变成 半个运维 一样… 刚好有需求写些部署工具，于是了解到了 fabric这个模块。下面简单带过一下 什么是Fabric 引用fabric主页的介绍 Fabric is a high level Python (2.7, 3.4+) library designed to execute shell commands remotely over SSH, yielding useful Python objects in return 意思就是Fabric是基于SSH的远程执行命令，并返回可调用的python对象的框架 Fabric 2.x的版本与 1.x相比，除了支持 python3之外，还做了很多改动。网上很多博客都写的是 1.x的版本，参考时要注意。 这里主要分析 2.x的版本 安装什么的就不废话了，下面来用一下 参照他的示例: 1234567 &gt;&gt;&gt; from fabric import Connection&gt;&gt;&gt; result = Connection('web1.example.com').run('uname -s')&gt;&gt;&gt; msg = "Ran &#123;.command!r&#125; on &#123;.host&#125;, got this stdout:\n&#123;.stdout&#125;"&gt;&gt;&gt; print(msg.format(result))Ran "uname -s" on web1.example.com, got this stdout:Linux 一目了然 下面在公司服务器上测试一下 123456789101112131415161718192021 # 服务器ip: 10.10.22.13# 用户: root&gt;&gt;&gt; from fabric import Connection&gt;&gt;&gt; result = Connection('10.10.22.13', user='root').run('uname -s')&gt;&gt;&gt; msg = "Ran &#123;.command!r&#125; on &#123;.host&#125;, got this stdout:\n&#123;.stdout&#125;"&gt;&gt;&gt; print(msg.format(result))Traceback (most recent call last): File "/Users/yang/workspace/PycharmProjects/FP-project/inventory_allocate/test/fabric_test.py", line 10, in &lt;module&gt; result = Connection("10.10.22.13", user='root').run("uname -s") File "&lt;decorator-gen-3&gt;", line 2, in run File "/Users/yang/anaconda3/lib/python3.6/site-packages/fabric/connection.py", line 29, in opens self.open() File "/Users/yang/anaconda3/lib/python3.6/site-packages/fabric/connection.py", line 501, in open self.client.connect(**kwargs) File "/Users/yang/anaconda3/lib/python3.6/site-packages/paramiko/client.py", line 424, in connect passphrase, File "/Users/yang/anaconda3/lib/python3.6/site-packages/paramiko/client.py", line 715, in _auth raise SSHException('No authentication methods available')paramiko.ssh_exception.SSHException: No authentication methods available 呵呵，我他妈就知道，代码里一行ssh的参数毛都没见到，这么容易连上就有鬼了（微笑 没的说，填坑要紧 源码分析 分析报错 12345678910111213 Traceback (most recent call last): File "/Users/yang/workspace/PycharmProjects/FP-project/inventory_allocate/test/fabric_test.py", line 10, in &lt;module&gt; result = Connection("10.10.22.13", user='root').run("uname -s") File "&lt;decorator-gen-3&gt;", line 2, in run File "/Users/yang/anaconda3/lib/python3.6/site-packages/fabric/connection.py", line 29, in opens self.open() File "/Users/yang/anaconda3/lib/python3.6/site-packages/fabric/connection.py", line 501, in open self.client.connect(**kwargs) File "/Users/yang/anaconda3/lib/python3.6/site-packages/paramiko/client.py", line 424, in connect passphrase, File "/Users/yang/anaconda3/lib/python3.6/site-packages/paramiko/client.py", line 715, in _auth raise SSHException('No authentication methods available')paramiko.ssh_exception.SSHException: No authentication methods available 我们可以看到调用堆栈上的错误回溯，定位到 line 501，在实例化 Connection对象后调用 client.connect(**kwargs)时抽了… 直接摸过去，从 Connection类出发往他祖宗上刨，下面先给出继承关系和 Connection的关键部分，然后逐块拆分说明: connection.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110 class Connection(Context): host = None original_host = None user = None port = None ssh_config = None gateway = None forward_agent = None connect_timeout = None connect_kwargs = None client = None transport = None _sftp = None _agent_handler = None def __init__( self, host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, ): # config super(Connection, self).__init__(config=config) if config is None: config = Config() elif not isinstance(config, Config): config = config.clone(into=Config) self._set(_config=config) # host相关 shorthand = self.derive_shorthand(host) host = shorthand["host"] err = ( "You supplied the &#123;&#125; via both shorthand and kwarg! Please pick one." # noqa ) if shorthand["user"] is not None: if user is not None: raise ValueError(err.format("user")) user = shorthand["user"] if shorthand["port"] is not None: if port is not None: raise ValueError(err.format("port")) port = shorthand["port"] # ssh_config self.ssh_config = self.config.base_ssh_config.lookup(host) # original_host self.original_host = host # host self.host = host if "hostname" in self.ssh_config: self.host = self.ssh_config["hostname"] # user self.user = user or self.ssh_config.get("user", self.config.user) # port self.port = port or int(self.ssh_config.get("port", self.config.port)) if gateway is None: if "proxyjump" in self.ssh_config: hops = reversed(self.ssh_config["proxyjump"].split(",")) prev_gw = None for hop in hops: if prev_gw is None: cxn = Connection(hop) else: cxn = Connection(hop, gateway=prev_gw) prev_gw = cxn gateway = prev_gw elif "proxycommand" in self.ssh_config: gateway = self.ssh_config["proxycommand"] else: gateway = self.config.gateway self.gateway = gateway # forward_agent if forward_agent is None: forward_agent = self.config.forward_agent if "forwardagent" in self.ssh_config: map_ = &#123;"yes": True, "no": False&#125; forward_agent = map_[self.ssh_config["forwardagent"]] self.forward_agent = forward_agent # connect_timeout if connect_timeout is None: connect_timeout = self.ssh_config.get( "connecttimeout", self.config.timeouts.connect ) if connect_timeout is not None: connect_timeout = int(connect_timeout) self.connect_timeout = connect_timeout # connect_kwargs self.connect_kwargs = self.resolve_connect_kwargs(connect_kwargs) # client client = SSHClient() client.set_missing_host_key_policy(AutoAddPolicy()) self.client = client # transport self.transport = None 重要的成员变量 class Connection 123456789 host = None # 主机名或IP地址: www.host.com, 66.66.66.66original_host = None # 同hostuser = None # 系统用户名: root, someoneport = None # 端口号（远程执行某些应用需提供）gateway = None # 网关forward_agent = None # 代理connect_timeout = None # 超时时间connect_kwargs = None # 连接参数（记住这个，非常重要）client = None # 客户端 构造函数参数 Connection.__init__() 12345678 hostuser=Noneport=Noneconfig=Nonegateway=Noneforward_agent=Noneconnect_timeout=Noneconnect_kwargs=None 这些就是我们在实例化 Connection对象时可以控制的一些部分，比较重要的有 config和 connection_kwargs 构造函数主体 config Connection.__init__() 123456 super(Connection, self).__init__(config=config)if config is None: config = Config()elif not isinstance(config, Config): config = config.clone(into=Config)self._set(_config=config) config成员变量是一个 Config对象，它是调用父类 Context.__init__()方法来初始化的。 Context.__init__()定义如下: class Context 12345678910 class Context(DataProxy): def __init__(self, config=None): config = config if config is not None else Config() self._set(_config=config) command_prefixes = list() self._set(command_prefixes=command_prefixes) command_cwds = list() self._set(command_cwds=command_cwds) 具体过程是 Context.__init__()初始化时调用 _set()绑定了 Config成员对象 _config: class DataProxy 12345 def _set(self, *args, **kwargs): if args: object.__setattr__(self, *args) for key, value in six.iteritems(kwargs): object.__setattr__(self, key, value) 再通过加了 @property的 config()函数，使得 connection对象能直接用 self.config来引用 _config: class DataProxy 1234567 @propertydef config(self): return self._config@config.setterdef config(self, value): self._set(_config=value) host, user, port Connection.__init__() 12345678910111213 shorthand = self.derive_shorthand(host)host = shorthand["host"]err = ( "You supplied the &#123;&#125; via both shorthand and kwarg! Please pick one." # noqa)if shorthand["user"] is not None: if user is not None: raise ValueError(err.format("user")) user = shorthand["user"]if shorthand["port"] is not None: if port is not None: raise ValueError(err.format("port")) port = shorthand["port"] 这段是处理 host参数的。 host可以有下面集中传入形式: 1234 user@host:port # 例如: root@10.10.10.10:6666user@host # 例如: root@10.10.10.10host:port # 例如: 10.10.10.10:6666host # 例如: 10.10.10.10 前三种会调用 self.derive_shorthand(host)分别解析出 self.host， self.user和 self.port，最后一种需单独传入 user， port。 如果用前三种传入方式的话，记得不要再重复传入 user或 port了，会抛出异常 源码是真他妈长啊，注释就占了一两百行 (微笑 ok，初始化的参数我们先到这里，因为它给的示例也就只有个 host而已，一会再讲 config_kwags和深入下 config。我们现在先去报错的地方: class Connection 123456789101112131415 kwargs = dict( self.connect_kwargs, username=self.user, hostname=self.host, port=self.port,)if self.gateway: kwargs["sock"] = self.open_gateway()if self.connect_timeout: kwargs["timeout"] = self.connect_timeout# Strip out empty defaults for less noisy debuggingif "key_filename" in kwargs and not kwargs["key_filename"]: del kwargs["key_filename"]# Actually connect!self.client.connect(**kwargs) # 就是你了 看到最后一行，传参时将字典 kwargs传了过去， kwargs里除了 usr， host， port之外，还有一个 connect_kwargs。我们看看 client.connect()的定义: 12345678910111213141516171819202122 def connect( self, hostname, port=SSH_PORT, username=None, password=None, # 你 pkey=None, # 你 key_filename=None, # 还有你 timeout=None, allow_agent=True, look_for_keys=True, compress=False, sock=None, gss_auth=False, gss_kex=False, gss_deleg_creds=True, gss_host=None, banner_timeout=None, auth_timeout=None, gss_trust_dns=True, passphrase=None, ) 看到 6, 7, 8行没？that’s it. 接下来我们改写一下一开始的示例: 使用 password: 123456 &gt;&gt;&gt; from fabric import Connection&gt;&gt;&gt; # my_password为10.10.22.13的root用户密码&gt;&gt;&gt; conn = Connection('10.10.22.13', user='root', connect_kwargs=&#123;'password': '$&#123;my_password&#125;'&#125;)&gt;&gt;&gt; conn.run("uname -s")Linux 使用 key_filename: 1234567 &gt;&gt;&gt; from fabric import Connection&gt;&gt;&gt; # 使用key_filename参数前提需将你的ssh公钥（.pub后缀）添加到远程服务器的.ssh/authorized_keys file里&gt;&gt;&gt; # id_rsa为私钥&gt;&gt;&gt; conn = Connection('10.10.22.13', user='root', connect_kwargs=&#123;'key_filename': '$&#123;path to local .ssh dir&#125;/$&#123;your id_rsa file&#125;'&#125;)&gt;&gt;&gt; conn.run("uname -s")Linux 朋友们，让我们举杯庆祝一下吧 connect_kwargs 我们趁此机会窥视一下 connect_keargs的相关部分 Connection.__init__() 1 self.connect_kwargs = self.resolve_connect_kwargs(connect_kwargs) 我们看到，当 connect_kwargs为 None时，会通过 config成员变量动态增加属性 connect_kwargs属性: Connection.resolve_connect_kwargs() 123456789101112131415 def resolve_connect_kwargs(self, connect_kwargs): if connect_kwargs is None: connect_kwargs = self.config.connect_kwargs # 调用__getattr__()动态增加属性 elif "key_filename" in self.config.connect_kwargs: kwarg_val = connect_kwargs.get("key_filename", []) conf_val = self.config.connect_kwargs["key_filename"] connect_kwargs["key_filename"] = conf_val + kwarg_val if "identityfile" in self.ssh_config: connect_kwargs.setdefault("key_filename", []) connect_kwargs["key_filename"].extend( self.ssh_config["identityfile"] ) return connect_kwargs 在 __getattr__方法里又调用了类方法 _get()将 connect_kwargs传到 key: DataProxy.__getattr__() 12345678910111213 def __getattr__(self, key): try: return self._get(key) # 调用_get() except KeyError: if key in self._proxies: return getattr(self._config, key) err = "No attribute or config key found for &#123;!r&#125;".format(key) attrs = [x for x in dir(self.__class__) if not x.startswith('_')] err += "\n\nValid keys: &#123;!r&#125;".format( sorted(list(self._config.keys())) ) err += "\n\nValid real attributes: &#123;!r&#125;".format(attrs) raise AttributeError(err) 调用 _get()后返回一个 DataProxy对象 value: DataProxy._get() 1234567891011121314151617 def _get(self, key): if key in ( '__setstate__', ): raise AttributeError(key) value = self._config[key] if isinstance(value, dict): keypath = (key,) if hasattr(self, '_keypath'): keypath = self._keypath + keypath root = getattr(self, '_root', self) value = DataProxy.from_data( data=value, root=root, keypath=keypath, ) return value 是不是晕了？呵呵没关系，我他妈也是。就让他随风而去吧 fab命令 安装完 fabric后会连同 fab工具一起装到 python/bin下，在终端输入 fab -h查看命令参数 简单来说， fab干这么件事， 直接执行当前目录下的 fabfile.py脚本里的函数，下面介绍具体如何写 fabfile.py 首先按照国际惯例，导入包: 12 from fabric import Connectionfrom invoke import task 实例化 COnnection对象: 12 # $&#123;&#125;里的内容自行填充conn = Connection("$&#123;remote host&#125;", user='$&#123;remote user&#125;', connect_kwargs=&#123;'password': "$&#123;remote user's password&#125;"&#125;) 定义一个功能函数: 123 @taskdef execute(c): conn.run("uname -s") 这个 @task装饰器是必须加的，保证 fab能直接执行，参数 c不用管它，但不能定义成与你实例化的 conn同名，原因后面会说 保存为 fabfile.py: fabfile.py 12345678 from fabric import Connectionfrom invoke import taskconn = Connection("$&#123;remote host&#125;", user='$&#123;remote user&#125;', connect_kwargs=&#123;'password': "$&#123;remote user's password&#125;"&#125;)@taskdef execute(c): conn.run("uname -s") 在终端执行（服务器系统为Linux）: 12 $ fab executeLinux # Linux下的输出 说回参数 c， c在这里实际上是本地连接，是 localhost的一个 Connection对象。我们可以试一下: fabfile.py 123456 from fabric import Connectionfrom invoke import task@taskdef execute(c): c.run("uname -s") 在终端执行（我的系统为Mac）: 12 $ fab executeDarwin # Mac下的输出 一目了然 到这里大家应该大致明白 fab是干啥的了。这样的玩法就多了，下面举几个例子: fabfile.py 123456789101112131415161718192021 from fabric import Connectionfrom invoke import taskconn = Connection("$&#123;remote host&#125;", user='$&#123;remote user&#125;', connect_kwargs=&#123;'password': "$&#123;remote user's password&#125;"&#125;)@taskdef uname_local(c): c.run("uname -s")# 列出某路径下的文件@taskdef ls_remote(c, dir_path): with conn.cd(dir_path): conn.run("ls -la")# 还能在函数里实例化Connection对象@taskdef uname_rmt(c, host, user, password): con = Connection(host, user=user, connect_kwargs=&#123;'password': password&#125;) con.run("uname -s") 执行: 123456789 $ fab uname_localDarwin$ fab ls_remote /hometrendytd_root$ fab uname_rmt 10.10.22.13 root ******* # 这个密码就不放出来了Linux 具体的 Connection还封装了哪些命令，就需要大家在使用中探索了 fab 1.x 与 fab 2.x fab 1.x与 fab 2.x最大的不同就是 fab 2.x没有了 env模块，所有的操作都基于 Connection对象完成，对于 fab命令的调用，将暴露方法封装到 invoke模块，使其独立出来。这是我觉得最大的不同。只是现在还没有很多的博客写到 fab 2.x的一些特性，官方文档也很简单，还是需要大家花时间阅读下源码才能清楚里面的逻辑 有时间的话会再对 fabric做个详细剖析]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>fabric</tag>
        <tag>远程部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器安装anaconda与配置jupyter反向代理]]></title>
    <url>%2Fposts%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E8%A3%85anaconda%E4%B8%8E%E9%85%8D%E7%BD%AEjupyter%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[最近在公司的服务器上搭环境和工具，折腾了一小会，记录一下 安装Anaconda 公司服务器系统信息: Linux version: 4.4.0-116-generic (buildd@lgw01-amd64-021) Distribution: Ubuntu 16.04.4 LTS gcc version: 5.4.0 20160609 CPU info: 32 Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz (双物理cpu，单个cpu 8核16线程…) 内网ip: 10.10.22.13 首先 ssh到服务器， cd到一个非系统级的目录，下载anaconda安装脚本: wget https://mirrors4.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.1.0-Linux-x86_64.sh 执行安装脚本: sh Anaconda3-5.1.0-Linux-x86_64.sh 若中途问你是否添加环境变量，请选择否，不然会覆盖系统的python环境变量 安装位置自选 设置软链接至 usr/local/bin: 因为不设置环境变量，所以这一步是方便我们可以在命令行直接输入 可执行文件名 执行 anaconda3/bin 下的可执行文件，如 jupyter 1234567 # 将anaconda3/bin/python解释器运行脚本软链接至/usr/local/bin/python36，python36可换成其他你喜欢的名字ln -s $&#123;path to anaconda3&#125;/bin/python /usr/local/bin/python36# 将anaconda3/bin/jupyter运行脚本软链接至/usr/local/bin/jupyterln -s $&#123;path to anaconda3&#125;/bin/jupyter /usr/local/bin/jupyter# 还有什么要软链过去的请参照上面自便 在终端输入 python36， jupyter查看是否生效 服务器配置jupyter 到重头戏了 这里有两个需求: 在公司内网能访问到juoyter服务的端口 在家时连上公司VPN能访问到jupyter服务的端口 首先生成jupyter配置文件 执行下面的命令: 1 jupyter notebook --generate-config 配置文件会生成在以下路径: Windows: C:\Users\USERNAME\.jupyter\jupyter_notebook_config.py OS X: /Users/USERNAME/.jupyter/jupyter_notebook_config.py Linux: /home/USERNAME/.jupyter/jupyter_notebook_config.py 生成密码与加密后的hash串 执行下面的命令，输入设定的密码 1 jupyter notebook password hash文件生成在以下路径: Windows: C:\Users\USERNAME\.jupyter\jupyter_notebook_config.json OS X: /Users/USERNAME/.jupyter/jupyter_notebook_config.json Linux: /home/USERNAME/.jupyter/jupyter_notebook_config.json 配置 jupyter_notebook_config.py 先 cd进 .jupyter目录，然后 vim jupyter_notebook_config.py进行修改 在顶部添加下面的配置: 123456 c.NotebookApp.allow_origin = '*'c.NotebookApp.ip = '*'c.NotebookApp.open_browser = Falsec.NotebookApp.password = u"sha1:bb7b06..." # 这里将jupyter_notebook_config.json里的sha1串复制过来c.NotebookApp.port = 9999 # 端口可设为其他，注意不要冲突c.NotebookApp.trust_xheaders = True 配置hosts 以我的为例 1 10.10.22.13 fp-bd13 启动jupyter 用nohup在后台启动: 1 nohup jupyter notebook --allow-root &amp; 浏览器访问 http://fp-bd13:9999，看看效果。 Tips: jupyter新的jupyter lab比notebook做了一些优化，界面也高端很多。只要在url后面加 /lab就能立即享用 http://fp-bd13:9999/lab 配置反向代理 这一步是最坑爹的 我们公司内部的vpn统一登上这台服务器 172.17.22.229，然后通过它再连 10.10.22.*的机器。所以需要在 172.17.22.229的nginx上配置反向代理，这样我们就能在外面访问到jupyter了 折腾了N久，最终配置如下: 123456789101112131415161718 map $http_upgrade $connection_upgrade &#123; default upgrade; &apos;&apos; close;&#125;server&#123; server_name fp.bd13.dev.jupyter; location / &#123; proxy_pass http://10.10.22.13:9999; proxy_redirect off; proxy_set_header HOST $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; &#125;&#125; 重新加载下nginx的配置，在浏览器访问 fp.bd13.dev.jupyter就能愉快地玩耍啦]]></content>
      <categories>
        <category>技术杂项</category>
      </categories>
      <tags>
        <tag>anaconda</tag>
        <tag>jupyter</tag>
        <tag>nginx</tag>
        <tag>反向代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (Week4)]]></title>
    <url>%2Fposts%2FMachine-Learning%20(Week4)%2F</url>
    <content type="text"><![CDATA[第四周的课程开始介绍 Neural Networks - 神经网络 的概念，包括它的 结构 和 表示方法。 Neural Networks: Representation - 神经网络：表述 Non-linear hypotheses - 非线性假设 我们之前所讲到的，线性回归和逻辑回归，它们在进行 非线性预测和分类 时，在 特征比较少 的情况下，用 特征多项式 来训练会有不错的表现（如下式，两个特征）。 $\theta_{0} + \theta_{1}x_{1}^{2} + \theta_{2}x_{1}x_{2} + \theta_{3}x_{2}^{2}$ 但是一旦特征变多，比如几十甚至上百个时，利用特征多项式训练，所组合出来的新特征将会是一个非常庞大的数字（如下式，100个特征，仅两两组合）。这无疑是行不通的。 $\theta_{0} + \theta_{1}x_{1}^{2} + \theta_{2}x_{2}^{2} + \theta_{3}x_{3}^{2} + \cdots + \theta_{100}x_{100}^{2} + \theta_{101}x_{1}x_{2} + \theta_{102}x_{1}x_{3} + \cdots + \theta_{10000}x_{99}x_{100}$ 所以，我们需要一种新的模型，就是 神经网络。 Neurons and the brain - 神经元和大脑 这部分是介绍神经网络的一些背景，若不感兴趣可 点此跳至下一节 首先神经网络是模仿大脑结构来建立的。我们大脑可以学习很多事情，小到一个行为，一个动作，大到一门学科，一门语言，如果我们想让计算机来处理不同的学习任务，似乎我们需要针对性的编写不同的程序来实现。可是人脑在学习的时候真的用了这么多不同的“算法”么？我们能不能假设其实大脑只有一种学习算法，但却可以处理很多的事情？下面我们来看一下关于这个假设的一些证据。 科学家将小白鼠的 耳朵 到 听觉皮层 的 听觉神经 剪断，然后将 视觉神经 接到 听觉皮层 上，结果， 听觉皮层 学会了 看。 美国食品和药物管理局在临床实验一个名为brainport的系统，能帮助失明人士 看见 东西。它是这样工作的：在失明人士头上带一个灰度摄像头，获取面前场景的低分辨率灰度图像，然后将信号连接到 舌头 上的一个很薄的 电极阵列 上，这样 每个像素点都能映射到舌头的某个位置，这种系统能让人在几十分钟内用舌头学会 看东西。 这些例子说明，我们大脑的每一块区域，都能处理不同的信息，图像，声音，触觉，嗅觉等等，就好比一个机器可以接受任何传感器输入的信号。如果我们找出 大脑的学习方法，然后在计算机上实现，这也许是真正的迈向人工智能。而 神经网络 则是第一步。 下面我们将深入到神经网络的细节。 Model representation I - 模型表示 1 每一个神经元，也可以叫一个 计算节点，它接受来自 前一个神经元的输出 作为 它的输入，然后经过 计算，将 输出 送给 下一个神经元 作为其 输入。 graph LR; a1((a1)) -- input --> a2((a2)); a2((a2)) -- output --> a3((a3)); 比如一个以 逻辑回归 为模型的网络可以表示成这样： 这是一个只有 两层 的神经网络，只包含 输入层 和 输出层。 下面我们看一个3层的神经网络： 其中layer 2是 隐藏层，是中间的计算单元，将结果反馈到下一层。这里我们定义一下符号表示： $a_{i}^{(j)}$ 为第j层第i个节点 $h_{\Theta}(x)$ 为输出结果 &nbsp;未完待续…有空继续…]]></content>
      <categories>
        <category>机器学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+NexT+GithubPages+CodingPages+GiteePages+Travis全攻略]]></title>
    <url>%2Fposts%2FHexo%20%2B%20NexT%20%2B%20Github%20Pages%20%2B%20Coding%20Pages%20%2B%20Gitee%20Pages%20%2B%20Travis%20%E5%85%A8%E6%94%BB%E7%95%A5%2F</url>
    <content type="text"><![CDATA[这几天刚更新了NexT主题，一直在修改细节，终于从5.1.x的版本更新到了6.0.x的版本，nodeJS和NPM也做了更新。本着 互联网共享精神，我在这里将 如何搭建Hexo+NexT博客和如何规范化写作+构建+push的流程 做详细整理。 本人目前常用 Mac。以下配置对于 Windows，Linux 自行参考。 安装Hexo 安装node.js 如果你已经安装了node.js，请忽略。 访问 node.js官网，根据指引进行安装。 安装Git 如果你已经安装了Git，请忽略。 访问 Git官网，根据指引进行安装。 由于众所周知的原因，Windows从上面的链接下载git for windows最好挂上一个代理，否则下载速度十分缓慢。也可以参考 这个页面，收录了存储于百度云的下载地址。 安装Hexo 国内的朋友，因为众所周知的原因，从npm直接安装hexo会非常慢，所以你需要用到 镜像源 ，参考上面的步骤，使用cnpm命令行工具代替默认的npm: 在windows控制台（cmd）里输入并执行 npm install -g cnpm --registry=https://registry.npm.taobao.org，然后安装hexo: cnpm install -g hexo-cli 国外的朋友，请直接打开windows控制台，输入 npm install -g hexo-cli并执行。 建站 建立本地博客文件夹 在命令行执行如下命令，其中 &lt;folder&gt;为文件夹路径 12 hexo init &lt;folder&gt;cd &lt;folder&gt; 示例 12 hexo init C:/hexo/myblogcd C:/hexo/myblog 以下步骤均采用这个路径作为说明，并且 所有有关 hexo的命令 均要在此路径下执行。 建立好后文件夹目录如下 123456789 .├── _config.yml├── package.json├── .gitignore├── node_modules├── scaffolds├── source| ├── _posts└── themes 其中 _config.yml：博客的配置文件，可以在此配置大部分的参数。 package.json：应用程序的信息。EJS, Stylus和Markdown renderer 已默认安装，您可以自由移除。 package.json 12345678910111213141516171819 &#123; "name": "hexo-site", "version": "0.0.0", "private": true, "hexo": &#123; "version": "" &#125;, "dependencies": &#123; "hexo": "^3.2.0", "hexo-generator-archive": "^0.1.4", "hexo-generator-category": "^0.1.3", "hexo-generator-index": "^0.2.0", "hexo-generator-tag": "^0.2.0", "hexo-renderer-ejs": "^0.3.0", "hexo-renderer-stylus": "^0.3.1", "hexo-renderer-marked": "^0.3.0", "hexo-server": "^0.2.0" &#125;&#125; scaffolds：模板文件夹，当您新建文章时，Hexo会根据scaffold来建立文件。 source：资源文件夹，存放用户资源的地方。除 _posts文件夹之外，开头命名为 _ (下划线)的文件/文件夹和隐藏的文件将会被忽略。Markdown和HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes：主题文件夹。Hexo会根据主题来生成静态页面。 node_modules：node.js模块，一些 插件 和 依赖 会被安装到这里。 更加详细的解释请参考 hexo官方文档 安装NexT主题 进入本地博客文件夹并将NexT主题 clone至 themes文件夹下 12 cd C:/hexo/mybloggit clone https://github.com/theme-next/hexo-theme-next themes/next 接着，进入 ./themes/next/文件夹，将 隐藏文件夹 .git删除。这一步是为了后面将网站源码push到github上的 必要工作。 你会看到，在 next下也有一个 _config.yml的文件，这是 NexT主题的配置文件，为了区别它和 博客配置文件，下面会用带路径的文件名来描述它们： myblog/_config.yml：博客配置文件 next/_config.yml：主题配置文件 启用NexT主题 在 myblog/_config.yml里 theme:选项填 next，=&gt; theme: next，注意冒号后空一格。 到这里，建站的任务就完成了。你现在可以打开控制台，输入并执行如下命令： 12 cd C:/hexo/mybloghexo g &amp;&amp; hexo s 其中 hexo g：新建 public文件夹，并在其中生成网站静态文件（html，css，等文件） hexo s：启动hexo服务器，默认情况下，访问网址为： http://localhost:4000/ 更多有关hexo的命令，请参考 hexo官方文档的 命令部分。 你会看到控制台有如下输出： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 INFO Start processingINFO Files loaded in 624 msINFO Generated: index.htmlINFO Generated: archives/index.htmlINFO Generated: images/algolia_logo.svgINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/avatar.gifINFO Generated: images/cc-by-nc.svgINFO Generated: images/apple-touch-icon-next.pngINFO Generated: images/cc-by-sa.svgINFO Generated: images/cc-by.svgINFO Generated: images/cc-zero.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/favicon-32x32-next.pngINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/loading.gifINFO Generated: images/placeholder.gifINFO Generated: images/logo.svgINFO Generated: images/quote-r.svgINFO Generated: images/quote-l.svgINFO Generated: images/searchicon.pngINFO Generated: archives/2018/01/index.htmlINFO Generated: archives/2018/index.htmlINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: css/main.cssINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/velocity/velocity.min.jsINFO Generated: lib/font-awesome/bower.jsonINFO Generated: lib/velocity/velocity.jsINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: lib/jquery/index.jsINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: js/src/affix.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.min.jsINFO Generated: js/src/bootstrap.jsINFO Generated: js/src/motion.jsINFO Generated: js/src/js.cookie.jsINFO Generated: js/src/exturl.jsINFO Generated: js/src/algolia-search.jsINFO Generated: js/src/post-details.jsINFO Generated: js/src/scrollspy.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.pack.jsINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: js/src/utils.jsINFO Generated: js/src/scroll-cookie.jsINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: 2018/01/22/hello-world/index.htmlINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: js/src/schemes/pisces.jsINFO 50 files generated in 865 msINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 在浏览器地址栏输入 http://localhost:4000/并访问，你应该会看到如下页面： &nbsp; 恭喜你！你已经完成了博客搭建的主要工作！接下来就是细节的配置了。请耐心阅读以下内容。 配置博客配置文件 整个 myblog/_config.yml的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980 # Hexo Configuration## Docs: https://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: Hexosubtitle:description:author: John Doelanguage:timezone:# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.comroot: /permalink: :year/:month/:day/:title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: true # Open external links in new tabfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true auto_detect: false tab_replace: # Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: path: '' per_page: 10 order_by: -date # Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ss# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: page# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: next# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: 博客基础配置 这里是配置博客基础的地方，包括 博客名， 小标题， 描述， 站长名（你的昵称）， 语言， 时区。 1234567 # Sitetitle: # 博客名subtitle: # 小标题description: # 描述author: # 你叫啥language: # 语言timezone: # 时区 下面是我的配置： 1234567 # Sitetitle: 淦subtitle: n*m*lg(b)description: 汝亦知射乎？吾射不亦精乎？author: tankeryanglanguage: zh-Hanstimezone: 你可以参考一下 哪项配置分别对应哪个位置，其中 language: zh-Hans这里是根据 主题是否支持 来设置的，因为渲染的js和css等文件都在主题里。NexT主题支持的语言 参考这里。hexo默认使用您计算机设置的时区。更改时区请参考 时区列表，比如如果您想换成 纽约时区，您需填 America/New_York。 注意，您在查看NexT支持的语言时访问的是 v5.x的 NexT使用文档，阅读时请注意。 v6.x的github地址在 这里，官网在 这里 博客url配置 这里是配置你的博客 链接格式 的，包括 主站 和 文章 链接。 123456 # URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yoursite.com # 博客链接root: / # 博客根目录permalink: :year/:month/:day/:title/ # 文章的永久链接格式permalink_defaults: # 永久链接中各部分的默认值 这是我的配置： 1234 url: https://tankeryang.github.ioroot: /permalink: posts/:title/permalink_defaults: 这里我的博客链接是 https://tankeryang.github.io，因为我是挂在github上的。 root设置为 /。如果你的博客是在 子目录 下，如 http://yoursite.com/child，你需这样设置： 12 url: http://yoursite.com/childroot: /child/ 接着是 permalink的配置，hexo默认的是 :year/:month/:day/:title/的格式。比如我点开博客搭建好之后的默认博文 Hello World，它的链接是这样的： http://localhost:4000/2018/01/22/hello-world/： 如果你想 更改文章永久链接格式 的话，以下是和链接格式有关的变量，你可以根据以下变量来配置： 变量 描述 :year 文章的发表年份（4 位数） :month 文章的发表月份（2 位数） :i_month 文章的发表月份（去掉开头的零） :day 文章的发表日期 (2 位数) :i_day 文章的发表日期（去掉开头的零） :title 文件名称 :id 文章 ID 更多有关链接的配置，请参考 hexo官方文档中的 永久链接部分。 &nbsp; 以下内容更新于2018/1/24，承接上文 配置资源文件夹 资源（Asset）代表source文件夹中除了文章以外的所有文件，例如图片、CSS、JS 文件等。比方说，如果你的Hexo项目中只有少量图片，那最简单的方法就是将它们放在 source/images 文件夹中。然后通过类似于 ![](/images/image.jpg)的方法访问它们。 如果你想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，Hexo也提供了更组织化的方式来管理资源。这个稍微有些复杂但是管理资源非常方便的功能可以通过将 config.yml文件中的 post_asset_folder选项设为 true来打开： 1 post_asset_folder: true # 设置为true 设置为 true后，当你新建一篇文章时，hexo同时会新建一个 和文章标题一样名字 的文件夹，你的文章所引用的图片等资源就可以放在这里面了。 将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过 标签插件 来引用它们，这样你就得到了一个更简单而且方便得多的工作流。关于什么是标签插件，接下来的内容会说明。请耐心阅读。（你也可以点击上面的链接浏览一下标签插件的内容） &nbsp; 以下内容更新于2018/1/25，承接上文（不好意思，本人很懒…） 写作 新建文章 执行如下命令新建文章： 1 hexo new [layout] &lt;title&gt; 其中 [layout]字段是文章的 布局，默认为 post，可以通过修改 _config.yml中的 default_layout参数来指定默认布局。 &lt;title&gt;则是文章标题。 布局 Hexo 有三种默认布局： post、 page和 draft，它们分别对应不同的路径，而您 自定义的其他布局 和 post相同，都将储存到 source/_posts文件夹。 布局 路径 post source/_posts page source draft source/_draft 其实布局我到现在也不是很清楚是什么， 我是这样认为的： 如果你执行了这条命令 hexo new post &quot;new article&quot;，hexo会新建一个 new article.md文件在 source/_post文件夹下。同理，其他两个布局参照上面的路径新建文章。 文件名称 Hexo默认以 标题 作为文件名称，你也可编辑 myblog/_config.yml中的 new_post_name参数来改变默认的文件名称，比如设置为： 1 new_post_name: :year-:month-:day-:title.md # File name of new posts 这样在 文章名 前面就会加上日期和时间共同组成 文件名。 下面是一些可用来配置文件名的变量： 变量 描述 :title 标题（小写，空格将会被替换为短杠） :year 建立的年份,比如，2015 :month 建立的月份（有前导零），比如， 04 i_month 建立的月份（无前导零），比如， 4 :day 建立的日期（有前导零），比如， 07 i_day 建立的日期（无前导零），比如， 7 更多有关 基本写作设置 的内容请参考 hexo官方文档的 写作部分。 下面，我们就来尝试一下吧！ 首先，执行 1 hexo new post "caonima" 你会看到输出 1 INFO Created: C:/hexo/myblog/source/_posts/caonima.md 同时，在 source/_post文件夹下多了 caonima.md文件和 caonima文件夹。 1234 .├── caonima.md├── hello-world.md├── caonima 打开 caonima.md，你会看到这些 12345 ---title: caonimadate: 2018-01-25 13:06:28tags:--- 这些是 front-matter，下面我会对它进行说明，请耐心阅读（ 这句话我到底讲了几次）。 接下来你可以随便在里面写点内容，比如： 123456789101112 # caonima## caonima### caonima__caonima___caonima_* caonima&gt; caonima[caonima]()~~caonima~~`caonima` 保存。执行下面语句生成博客文件并运行本地hexo服务端： 1 hexo g &amp;&amp; hexo s 你会看到如下输出： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 INFO Start processingINFO Files loaded in 642 msINFO Generated: 2018/01/22/hello-world/index.htmlINFO Generated: archives/index.htmlINFO Generated: index.htmlINFO Generated: archives/2018/01/index.htmlINFO Generated: archives/2018/index.htmlINFO Generated: images/avatar.gifINFO Generated: images/apple-touch-icon-next.pngINFO Generated: images/cc-by-nc-nd.svgINFO Generated: images/algolia_logo.svgINFO Generated: images/cc-by-nc-sa.svgINFO Generated: images/cc-by-nd.svgINFO Generated: images/cc-by-nc.svgINFO Generated: images/cc-by.svgINFO Generated: images/favicon-16x16-next.pngINFO Generated: images/cc-zero.svgINFO Generated: images/favicon-32x32-next.pngINFO Generated: images/cc-by-sa.svgINFO Generated: images/logo.svgINFO Generated: images/placeholder.gifINFO Generated: images/quote-l.svgINFO Generated: images/loading.gifINFO Generated: images/quote-r.svgINFO Generated: lib/font-awesome/HELP-US-OUT.txtINFO Generated: lib/font-awesome/css/font-awesome.css.mapINFO Generated: images/searchicon.pngINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woff2INFO Generated: lib/font-awesome/fonts/fontawesome-webfont.woffINFO Generated: js/src/algolia-search.jsINFO Generated: js/src/exturl.jsINFO Generated: js/src/affix.jsINFO Generated: js/src/post-details.jsINFO Generated: js/src/motion.jsINFO Generated: js/src/scroll-cookie.jsINFO Generated: js/src/utils.jsINFO Generated: js/src/scrollspy.jsINFO Generated: lib/font-awesome/bower.jsonINFO Generated: js/src/js.cookie.jsINFO Generated: js/src/bootstrap.jsINFO Generated: lib/velocity/velocity.ui.min.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.pack.jsINFO Generated: js/src/schemes/pisces.jsINFO Generated: lib/ua-parser-js/dist/ua-parser.min.jsINFO Generated: css/main.cssINFO Generated: lib/jquery/index.jsINFO Generated: lib/velocity/velocity.ui.jsINFO Generated: lib/font-awesome/css/font-awesome.cssINFO Generated: lib/velocity/velocity.min.jsINFO Generated: lib/font-awesome/css/font-awesome.min.cssINFO Generated: lib/velocity/velocity.jsINFO Generated: lib/font-awesome/fonts/fontawesome-webfont.eotINFO Generated: 2018/01/25/caonima/index.htmlINFO 51 files generated in 1 sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 在浏览器输入 http://localhost:4000/并访问，你会看到这样的页面： &nbsp; 恭喜你！你已经可以进行简单的文字创作了！下面的任务就是让你的写作流程规范化的细节。请耐心阅读。 标签插件 从上方跳转过来的朋友， &nbsp;点此返回 资源配置文件夹处 标签插件是用于在文章中快速插入特定内容的插件。 它的在文章中用法一般是这样： 123 &#123;% [某种标签] %&#125;&lt;你想插入的内容&gt;&#123;% end[某种标签] %&#125; 或者这样： 1 &#123;% [某种标签] &lt;你想插入的内容&gt; %&#125; 用例子说明最快： 比如像前面提到的， 用标签插件在文章引用图片，你只需这样写 1 &#123;% asset_img &lt;图片文件名&gt; %&#125; 示例 1 &#123;% asset_img caonima.jpg %&#125; 这是我最常用的标签了， asset_img，顾名思义，就是图片资源。一般我都用它来插入图片。因为我们在前面配置了 资源文件夹，所以 &lt;图片文件名&gt;这里我们不用输入绝对路径， 只需输入图片文件名 就ok了， hexo会自动在资源文件夹里寻找你的图片。 你可以在 caonima文件夹里放一张图片，然后在 caonima.md里用上面的 asset_img标签插件来引用它，看看效果。 更多有关标签插件的内容，请参考 hexo官方文档中的 标签插件部分。 配置主题配置文件 NexT主题作为hexo众多主题里最火的一款，除了简约美观的设计之外，最重要的一点就是 可定制化的程度高。你可以很轻松的 开启或关闭某些功能，甚至 自己尝试添加一些功能也比其他主题简单，因为它的 源文件组织得很清晰，主题的 布局， js， css， 字体， 语言，等文件都独立区分。 下面我会参照我的配置来详细介绍如何配置NexT主题。 重要更新 在 v6.0.x的版本里，NexT新增了 缓存 这样一个特性： 123 # Allow to cache content generation. Introduced in NexT v6.0.0.cache: enable: true 这是一个非常强大的改进！也就是说，当我们执行了 hexo s预览博客内容时，同时对 文章内容 或 主题配置 做了一些修改，我们只需 刷新一下 页面就能实时看到更改效果，而不用重新执行 hexo clean &amp;&amp; hexo g来重新生成页面。对此我只能说 6 6 6 6 6 6 网站图标 下面就是网站图标的配置项： 123456789 # For example, you put your favicons into `hexo-site/source/images` directory.# Then need to rename &amp; redefine they on any other names, otherwise icons from Next will rewrite your custom icons in Hexo.favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 参照注释，先在 myblog/source/路径下新建 images文件夹，找一张 16x16的 ico或者 png图标，放进 images文件夹（在哪里找图标请自行百度），比如 caonima.ico。 然后将 small选项设置为 /images/caonima.ico： 12 favicon: small: /images/caonima.ico 再将其他的选项注释掉（因为基本用不到）： 1234567 favicon: small: /images/caonima.ico #medium: /images/favicon-32x32-next.png #apple_touch_icon: /images/apple-touch-icon-next.png #safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 网站图标配置就完成了。关于其他选项你可以有空自己放些图标文件来玩玩看什么效果。 网站底部内容 这些在 footer选项的配置里： 12345678910111213141516171819202122 footer: # Specify the date when the site was setup. # If not defined, current year will be used. #since: 2015 # Icon between year and copyright info. icon: user # If not defined, will be used `author` from Hexo main config. copyright: # ------------------------------------------------------------- # Hexo link (Powered by Hexo). powered: true theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: true # Version info of NexT after scheme info (vX.X.X). version: true # ------------------------------------------------------------- # Any custom text can be defined here. #custom_text: Hosted by &lt;a target="_blank" rel="external nofollow" href="https://pages.coding.me"&gt;&lt;b&gt;Coding Pages&lt;/b&gt;&lt;/a&gt; 默认图标是 user 。假如你想个性化的话可以参照 fontawsome提供的图标来进行选择。下面是我的配置： 12345678910111213141516171819202122232425 footer: # Specify the date when the site was setup. # If not defined, current year will be used. since: 2017 # Icon between year and copyright info. icon: cog # spiner icon rotate: fa-spin fa-lg margin-bottom #rotate_plus : fa-plus fa-lg margin-bottom # If not defined, will be used `author` from Hexo main config. copyright: # ------------------------------------------------------------- # Hexo link (Powered by Hexo). powered: true theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: true # Version info of NexT after scheme info (vX.X.X). version: true # ------------------------------------------------------------- # Any custom text can be defined here. #custom_text: Hosted by &lt;a target="_blank" href="https://pages.github.com"&gt;GitHub Pages&lt;/a&gt; 菜单栏设置 这些在 menu选项里： 1234567891011121314151617181920212223 # ---------------------------------------------------------------# Menu Settings# ---------------------------------------------------------------# When running the site in a subdirectory (e.g. domain.tld/blog), remove the leading slash from link value (/archives -&gt; archives).# Usage: `Key: /link/ || icon`# Key is the name of menu item. If translate for this menu will find in languages - this translate will be loaded; if not - Key name will be used. Key is case-senstive.# Value before `||` delimeter is the target link.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, question icon will be loaded.menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons / item badges.menu_settings: icons: true badges: false ||后面的 icon对应的是 fontawsome相应的图标名。如果你想添加 about菜单的话，按照以下步骤： 在 myblog下新建 about文件夹 在 about文件夹下新增 index.md文件 在 index.md里添加内容 在 menu选项里添加 about: /about/ || user 刷新一下看看效果。你会发现多了一个 about菜单。用这样的办法可以自定义很多菜单目录。 主题布局 NexT主题提供了4种不同风格的主题布局，按需设置： 123456789 # ---------------------------------------------------------------# Scheme Settings# ---------------------------------------------------------------# Schemesscheme: Muse#scheme: Mist#scheme: Pisces#scheme: Gemini 侧边栏设置 这一项的内容有点多，先放配置文件，我们一个个看： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102 # ---------------------------------------------------------------# Sidebar Settings# ---------------------------------------------------------------# Posts / Categories / Tags in sidebar.site_state: true# Social Links.# Usage: `Key: permalink || icon`# Key is the link label showing to end users.# Value before `||` delimeter is the target permalink.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded.#social: #GitHub: https://github.com/yourname || github #E-Mail: mailto:yourname@gmail.com || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skypesocial_icons: enable: true icons_only: false transition: false # Dependencies: exturl: true in Tags Settings section below. # To encrypt links above use https://www.base64encode.org # Example encoded link: `GitHub: aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQ= || github` exturl: false# Follow me on GitHub banner in right-top corner.# Usage: `permalink || title`# Value before `||` delimeter is the target permalink.# Value after `||` delimeter is the title and aria-label name.#github_banner: https://github.com/yourname || Follow me on GitHub# Blog rollslinks_icon: linklinks_title: Linkslinks_layout: block#links_layout: inline#links: #Title: http://example.com/# Sidebar Avataravatar: # in theme directory(source/images): /images/avatar.gif # in site directory(source/uploads): /uploads/avatar.gif # You can also use other linking images. url: #/images/avatar.gif # If true, the avatar would be dispalyed in circle. rounded: false # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. rotated: false# Table Of Contents in the Sidebartoc: enable: true # Automatically add list number to toc. number: true # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero#creative_commons: by-nc-sa#creative_commons:sidebar: # Sidebar Position, available value: left | right (only for Pisces | Gemini). position: left #position: right # Sidebar Display, available value (only for Muse | Mist): # - post expand on posts automatically. Default. # - always expand for all pages automatically # - hide expand only when click on the sidebar toggle icon. # - remove Totally remove sidebar including sidebar toggle. display: post #display: always #display: hide #display: remove # Sidebar offset from top menubar in pixels (only for Pisces | Gemini). offset: 12 # Back to top in sidebar (only for Pisces | Gemini). b2t: false # Scroll percent label in b2t button. scrollpercent: false # Enable sidebar on narrow view (only for Muse | Mist). onmobile: false social: 这一项被注释掉了，我们先取消注释。配置内容就是对应的社交账号链接。 github_banner: 右上角的 follow me on github links: 放一些友情链接或其它的你想放的链接 avatar: 头像的一些设置 其余的设置参考他给出的注释说明配置即可。下面是我的配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697 # ---------------------------------------------------------------# Sidebar Settings# ---------------------------------------------------------------# Posts / Categories / Tags in sidebar.site_state: true# Social Links.# Usage: `Key: permalink || icon`# Key is the link label showing to end users.# Value before `||` delimeter is the target permalink.# Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, globe icon will be loaded.social: GitHub: https://github.com/tankeryang || github E-Mail: mailto:youngzyang@outlook.com || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skypesocial_icons: enable: true icons_only: false transition: true# Follow me on GitHub banner in right-top corner.# Usage: `permalink || title`# Value before `||` delimeter is the target permalink.# Value after `||` delimeter is the title and aria-label name.github_banner: https://github.com/tankeryang || Follow me on GitHub# Blog rollslinks_icon: linklinks_title: 博客镜像 &amp; 友情链接links_layout: block#links_layout: inlinelinks: 淦 - github: https://tankeryang.github.io 淦 - coding: https://tankeryang.coding.me 淦 - gitee: http://tankeryang.gitee.io 未知: https://deeeeeeeee.github.io 简单可依赖: https://www.tiexo.cn/ 刘伟的博客: https://darrenliuwei.com# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: url: /uploads/my.jpg rounded: true# Table Of Contents in the Sidebartoc: enable: true # Automatically add list number to toc. number: true # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false# Creative Commons 4.0 International License.# http://creativecommons.org/# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: by-nc-sa#creative_commons:sidebar: # Sidebar Position, available value: left | right (only for Pisces | Gemini). position: left #position: right # Sidebar Display, available value (only for Muse | Mist): # - post expand on posts automatically. Default. # - always expand for all pages automatically # - hide expand only when click on the sidebar toggle icon. # - remove Totally remove sidebar including sidebar toggle. #display: post display: always #display: hide #display: remove # Sidebar offset from top menubar in pixels (only for Pisces | Gemini). offset: 12 # Back to top in sidebar (only for Pisces | Gemini). b2t: true # Scroll percent label in b2t button. scrollpercent: true # Enable sidebar on narrow view (only for Muse | Mist). onmobile: true 个性化设置 因为NexT可配置的选项太多，在这里我就不一一展开了，下面在介绍两个个性化的设置 主题标签插件 关于标签插件，大家可以回顾一下前面的内容。NexT也自带了一些标签插件供用户使用 note 提示块标签，效果就像你看到的这个提示块 配置如下： 12345678910111213 # Note tag (bs-callout).note: # Note tag style values: # - simple bs-callout old alert style. Default. # - modern bs-callout new (v2-v3) alert style. # - flat flat callout style with background, like on Mozilla or StackOverflow. # - disabled disable all CSS styles import of note tag. style: flat icons: true border_radius: 2 # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6). # Offset also applied to label tag variables. This option can work with disabled note tag. light_bg_offset: 3 使用方法： 12345 &#123;% note class %&#125;Any content (support inline tags too).&#123;% endnote %&#125;# 支持的class: class : default | primary | success | info | warning | danger. label label标签，给文字加底色 配置如下： 12 # Label tag.label: true 使用方法： 123 &#123;% label class@Text %&#125;# 支持的class : default | primary | success | info | warning | danger. 选项卡 效果如下： 选项卡1 选项卡2 我是选项卡1 1 我是代码框1 我是选项卡2 1 我是代码框2 配置如下： 1234567 # Tabs tag.tabs: enable: true transition: tabs: true labels: true border_radius: 3 使用方法： 123456789101112131415 &#123;% tabs 选项卡1 选项卡2 %&#125;&lt;!-- tab 选项卡1 --&gt;我是选项卡1&#123;% codeblock %&#125;我是代码框1&#123;% endcodeblock %&#125; &lt;!-- endtab --&gt; &lt;!-- tab 选项卡2 --&gt;我是选项卡2&#123;% codeblock %&#125;我是代码框2&#123;% endcodeblock %&#125; &lt;!-- endtab --&gt;&#123;% endtabs %&#125; 更多设置请参考 v5.x版本的 NexT文档和最新的 v6.x版本的 NexT文档 配置Git与Travic-CI持续集成 这一步是最能体现 自动化博客写作流程 的关键。务必仔细阅读。 github，gitee，coding新建博客项目 在github上新开一个repo， repo名: USERNAME.github.io 同理， coding repo名: USERNAME ， gitee repo名: USERNAME USERNAME为你的github，gitee，coding用户名 pages服务参考： github， coding， gitee 添加.gitignore 进入 myblog文件夹，新增 .gitignore文件，若存在则检查是否与如下一致： .gitignore 1234567 .DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 设置travis关联USERNAME.github.io 先用github账号登陆 travis 勾选你的博客项目，顺便点旁边的 setting进入设置，参照图2来勾选： 为博客项目设置deploy key 这一步比较重要，这是travis能否访问你的repo的关键。按照下面的步骤配置： 在 myblog下新建一个 .travis文件夹，并进入 .travis文件夹 在 myblog/.travis下生成一个专门给travis用的 ssh key: 执行 ssh-keygen -t rsa -f travis_rsa -C &quot;your@email.com&quot;，遇到密码输入直接 enter回车，email记得替换 github博客项目添加travis_rsa.pub公钥 将 .travis下的 travis_rsa.pub的内容复制，按下图进入 Add deploy key界面，将内容粘贴， 并勾选可读写权限（一定不要遗漏!!!） coding过程同上 gitee因为项目的 deploy key不能设置可写入权限，所以只能将 travis_rsa.pub添加到个人的公钥 加密travis_rsa 先安装 gem（关于ruby，gem相关的安装这里就不列出来了，我相信你的动手能力:)） 接着安装travis命令行工具: sudo gem install travis 装好后，进入 myblog/.travis文件夹，在当前路径下执行如下命令： 12 travis login --autotravis encrypt-file travis_rsa -add 需要注意的是，travis命令行工具貌似在Windows下不太好使…因此需要换另外的方法使得travis能访问到github，coding和gitee上的博客项目，主要是通过 token 来访问。相关的配置百度一下就有很多教程，比ssh来的更简单。就是在 安全 性上差了一点，因为 token 是有操作所有 repo 的权限的… 加密完成后你会发现 .travis文件夹下多了个 travis_rsa.enc的文件，这个就是加密后的 travis_rsa。同时 myblog下也多了 .travis.yml文件。下面我们就配置一下 .travis.yml。 先将 .travis下的 travis_rsa， travis_rsa.pub删掉。 请记住一定要删掉！！！只保留加密文件 按照下面配置 .travis.yml: .travis.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 language: node_jsnode_js: stablebranches: only: - devbefore_install:# 解密SSH# encrypted_key和encrypted_id可以在travis里setting查看，具体位置参考下图- openssl aes-256-cbc -K $&#123;你的encrypted_xxxx_key&#125; -iv $&#123;你的encrypted_xxxx_iv&#125; -in .travis/travis_rsa.enc -out ~/.ssh/travis_rsa -d- chmod 600 ~/.ssh/travis_rsa- mv -fv .travis/config ~/.ssh/config# 安装hexo以及一些插件，没用到的可移除相关命令install:- npm install hexo-cli -g- npm install hexo-math --save- npm install hexo-generator-searchdb --save- npm install hexo-symbols-count-time --save- npm install hexo-generator-feed --save- npm install hexo-wordcount --save- npm install mermaid --save- npm install hexo-tag-mermaid --save- npm install hexo-tag-plantuml --save# 安装next主题插件，没用到的可移除相关命令before_script:- cd ./themes/next- git clone https://github.com/theme-next/theme-next-fancybox3 source/lib/fancybox- git clone https://github.com/theme-next/theme-next-jquery-lazyload source/lib/jquery_lazyload- git clone https://github.com/theme-next/theme-next-needmoreshare2 source/lib/needsharebutton- git clone https://github.com/theme-next/theme-next-pace source/lib/pace- git clone https://github.com/theme-next/theme-next-pangu.git source/lib/pangu- git clone https://github.com/theme-next/theme-next-reading-progress source/lib/reading_progress- cd ..- cd ..# 构建博客script:- hexo -version- hexo clean &amp;&amp; hexo gafter_script:# 设置环境- set -ev- export TZ='Asia/Shanghai'- cd ./public# 提交- git config user.name "USERNAME" # 你的github用户名- git config user.email "your@email.com" # 你的github邮箱- git init- git add .- git commit -m "Site updated:`date +"%Y-%m-%d %H:%M:%S"`"# push- git remote add coding git@git.coding.net:USERNAME/USERNAME.git # USERNAME为你的coding用户名- git remote add gitee git@gitee.com:USERNAME/USERNAME.git # USERNAME为你的gitee用户名- git push -u origin master -f- git push -u coding master -f- git push -u gitee master -f 最后，将你的本地博客目录与远程github博客项目关联 先初始化本地博客目录用git管理 123456 git initgit remote add origin git @github.com:USERNAME/USERNAME.github.io.gitgit checkout -b devgit add .git commit -m "first commit"git push -u origin dev 上 travis检查构建流程，看看是否有问题，有问题再根据日志进行 .travis.yml的修改 构建完成后，分享到朋友圈:) 之后写完文章只要 git push origin dev就ok了。注意要在 dev分支下进行。可以通过 git checkout dev切换分支 从年初开始写，一直到今天（2018-05-23）才写完…足以证明我是一个多么 懒到没谱持之以恒的人，这样的博主还不赶快献爱心一个？]]></content>
      <categories>
        <category>技术杂项</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>NexT</tag>
        <tag>Github Pages</tag>
        <tag>Coding Pages</tag>
        <tag>Gitee Pages</tag>
        <tag>Travis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[半次元爬虫 banciyuan-downloader v1.0 发布]]></title>
    <url>%2Fposts%2F%E5%8D%8A%E6%AC%A1%E5%85%83%E7%88%AC%E8%99%AB-banciyuan-downloader-v1-0%20%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[请勿用于商业用途 尊重coser的版权 转载图片请注明Cn及链接 今天突然看到一组 《小魔女学院》的cos图，小姐姐美炸了。 &nbsp;因为加载速度太慢，我只能调低了图片的分辨率，各位将就一下，想看原图的到上面的链接慢慢欣赏。 于是乎搜到了这位小姐姐 【cn:犬神洛洛子】 cos粉毛那位 这是她的 半次元主页 关注一波。想着有空写个爬虫来爬她的原图吧。结果越写添加的功能越多。现在这个版本我push到了 github，上面有详细的使用方法。 目前版本支持功能情况 根据 coser_id批量下载某个coser发布的主题的所有图片 图片保存在以 coser名 命名的文件夹内 图片按 coser发布的主题 分文件夹保存，文件夹以主题标题命名 若有相同标题的主题，则命名文件夹时会加上随机后缀防止文件名冲突 图片命名格式为 %num%.jpg/ %num%.png，其中 %num%为从 1开始的 编号 只下载 最新 发布的图片，本地已有的 不会 重复下载 支持 断点续传 （从断连主题的下一个主题开始下载，若断连主题没下载完，则会丢失一部分断连主题的图片，其余均不影响） 无须提供半次元账号即可下载 下载指定主题 智能下载 未下载过的主题 无须提前关注就可下载 粉丝可见的主题 运行环境及python包版本（本人） windows 10 1703-15063.674 python 3.6.1 beautifulsoup 4.5.3 requests 2.13.0 lxml 3.7.2 运行结果 FAQ 有何疑问可在 github发布 issue ，本人会尽量及时查看 疯狂打call 原图出处: 小魔女学园-主角三人搞事组cos 苏西·曼芭芭拉(粉毛) cn : 犬神洛洛子 亚可·卡嘉莉(黑毛) cn :real__yami 洛蒂·杨森(黄毛) cn : 樱群]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>二次元</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (Week3)]]></title>
    <url>%2Fposts%2FMachine%20Learning%20(Week3)%2F</url>
    <content type="text"><![CDATA[在第三周的课程里，介绍了 Logistic Regression - 逻辑斯谛回归问题，主要应用在 Classification - 分类上。还有 Regularization - 正则化，如何用来解决 Overfitting - 过拟合问题。 Logistic Regression - 逻辑斯谛回归 Classification - 分类问题 分类在日常中用在很多地方，比如邮件是否垃圾邮件，肿瘤是否良性。通过给定的特征与对应的类别，我们可以训练出一个能够进行分类的算法。相应的，垃圾邮件的特征可以是某些关键词，比如推销类的；而肿瘤的特征可以是肿瘤大小或者别的什么（不懂就不胡说了）。 这时我们的结果$y$就是离散化的数字。 如果是 Binary Classification - 二分类问题，$y$可以离散化为$y = 0 or 1$，对应 是/否， 大/小等抽象的结果。 如果是 Multiple Classification - 多分类问题，$y$可以离散化为 元素个数为类别个数的向量。比如我们需要对某组数据进行分类，训练样本中一共有$n$类，当前训练样本的$y$是属于第$i$类的，则令 $y = [0_{1},0_{2},\cdots,1_{i},\cdots,0_{n}]^{T}$ ，其中下标位置为对应类别。 这里我们先讨论 Binary Classification - 二分类问题。同样先来个例子。 假如我们有一组肿瘤大小与其对应性质（良性/恶性）的数据，特征只有一个，就是肿瘤大小，$y=1$和 红色X点代表恶性。如下图： 我们看到，假如我们用单纯的线性方程来拟合这组数据，按照图示定义，当 $h_{\theta} = \theta^{T}x &gt;0.5$ 时预测为恶性，则会与原数据 误差较大。显然单纯的线性方程很难做到精准的分类。 我们尝试换一种思路。可以看到，两种类型的数据在某一$x$值上会有明显的区分。在$x$左边是良性的，在$x$右边是恶性的。于是我们做如下分析： 令分界点 $x = \frac{-\theta_{0}}{\theta_{1}}$ ，则当 $x &gt; \frac{-\theta_{0}}{\theta_{1}}$ 即 $\theta^{T}x = \theta_{0}+\theta_{1}x &gt; 0$ 时，预测$y=1$，当 $x &lt; \frac{-\theta_{0}}{\theta_{1}}$ 即 $\theta^{T}x = \theta_{0}+\theta_{1}x &lt; 0$ 时，预测$y=0$。这样就能得到很好的分类效果。 同样的，多特征时也可以如此这般。比如两个特征时的情况： 因此我们只要一个函数 $g(\theta^{T}x)$ 当 $\theta^{T}x &gt; 0$ 时， $g(\theta^{T}x) &gt; 0.5$ 当 $\theta^{T}x &lt; 0$ 时， $g(\theta^{T}x) &lt; 0.5$ 最后令 $h_{\theta}(x) = g(\theta^{T}x)$ ，就ok了。 Hypothesis Representation - 假设函数的表示 接着上面的问题。我们给出这样一个函数 $g(z) = \frac{1}{1+e^{-z}}$ 它的图像如下 它满足下述性质 当 $z &gt; 0$ 时， $g(z) &gt; 0.5$ 当 $z &lt; 0$ 时， $g(z) &lt; 0.5$ 因此，我们只需令 $\theta^{T}x = z$ ，即 $g(\theta^{T}x) = \frac{1}{1+e^{-\theta^{T}x}}$ 则可得我们的假设函数 $h_{\theta}(x) = g(\theta^{T}x) = \frac{1}{1+e^{-\theta^{T}x}}$ 这里 $h_{\theta}(x)$ 实际上可以理解为如下 $h_{\theta}(x) = p(y = 1|x;\theta)$ 即输入 $x$ 的情况下，预测结果为 $1$ 的概率为 $h_{\theta}(x)$ 。 比如说这是一个良性/恶性肿瘤的分类问题，我们训练出了 $h_{\theta}(x)$ 。现在有一个肿瘤的各项特征为 $x$ ，我们要判断它是良性 $(y=1)$ 还是恶性 $(y=0)$ ，把 $x$ 丢进 $h_{\theta}(x)$ 里，结果为 $0.8$ ，那么我们就可以说这个肿瘤有 $80\%$ 的概率是良性的。假如我们设置了一个 阈值为 $0.7$ ，计算结果超过这个阈值就可以声明预测为真，那么在上面的情况中，我们就可以直接对病人说你的肿瘤是良性的，不用担心。 Decision Boundary - 判定边界 在逻辑斯谛回归中，我们一般 当 $h_{\theta}(x) &gt; 0.5$ ，即当 $\theta^{T}x &gt; 0$ 时，预测 $y=1$ 当 $h_{\theta}(x) &lt; 0.5$ ，即当 $\theta^{T}x &lt; 0$ 时，预测 $y=0$ 如下图（见上节） 此时 阈值为 $0.5$ 对于一般的问题， $0.5$ 的阈值足以胜任。可是假如是一些精确度要求很高的问题，就比如刚刚的判断肿瘤是否良性，或者判断是否得癌症等，那么就应该把 阈值设置得高点，预测结果更准确。毕竟是人命关天的事嘛:) 假如我们的样本分布不能线性划分，如下图所示 我们可以用一个非线性的边界（高次多项式）来划分。 Cost function - 代价函数 对于前面的回归问题，我们的代价函数是 所有误差的平方和取均值（实际上就是 方差） $J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{( i)}\right)^{2}$ 如果我们沿用这个计算方法，将逻辑斯谛回归的 $h_{\theta}(x) = g(\theta^{T}x) = \frac{1}{1+e^{-\theta^{T}x}}$ 代入进上式的话，我们的函数图像会呈现出下面一种状况 这是一个 非凸函数，它有许多的局部最小值，不利于用梯度下降法寻找全局最小值。 所以我们要对逻辑回归重新定义一个代价函数。 根据我们 $h_{\theta}(x)$ 的性质 当 $\theta^{T}x &gt; 0$ 时， $h_{\theta}(x) &gt; 0.5$ 当 $\theta^{T}x &lt; 0$ 时， $h_{\theta}(x) &lt; 0.5$ $h_{\theta}(x) \in (0, 1)$ 我们对代价函数作出如下定义 $$Cost\left( h_{\theta}\left( x \right), y \right) =\begin{cases} -log\left( h_{\theta}\left( x \right ) \right )&amp; \text{ if } y = 1 \\ -log\left( 1 - h_{\theta}\left( x \right ) \right )&amp; \text{ if } y = 0 \end{cases}$$ 它的函数图像和意义如下所示 当 $y = 1$ 时 它所反映的就是当样本结果 $y = 1$ 时，如果我们 $h_{\theta}(x)$ 输出也 $\rightarrow 1$ 的话，我们的误差就 $\rightarrow 0$ ；反之，如果我们 $h_{\theta}(x)$ 输出 $\rightarrow 0$ 的话，我们的误差就 $\rightarrow \infty$ 当 $y = 0$ 时 它所反映的就是当样本结果 $y = 0$ 时，如果我们 $h_{\theta}(x)$ 输出也 $\rightarrow 0$ 的话，我们的误差就 $\rightarrow 0$ ；反之，如果我们 $h_{\theta}(x)$ 输出 $\rightarrow 1$ 的话，我们的误差就 $\rightarrow \infty$ 没毛病:) Simplified cost function and gradient descent - 化简代价函数与梯度下降 对于 $Cost\left( h_{\theta}\left( x \right), y \right)$ ，我们可以化简成 $Cost\left( h_{\theta}\left( x \right), y \right) = -ylog\left( h_{\theta}\left( x \right) \right) - \left( 1-y \right)log\left( 1-h_{\theta}\left( x \right) \right)$ 对于 $J(\theta)$ 我们作如下定义 $J(\theta) = \frac{1}{m} \sum_{i=1}^{m}Cost\left( h_{\theta}\left( x^{\left( i \right)} \right), y^{\left( i \right) }\right)$ 将 $Cost\left( h_{\theta}\left( x \right), y \right)$ 代入上式，则可得 $J(\theta) = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{\left( i \right)}log\left( h_{\theta}\left( x^{\left( i \right)} \right) \right) + \left( 1-y^{\left( i \right)} \right)log\left( 1-h_{\theta}\left( x^{\left( i \right)} \right) \right) \right]$ 这时我们就可以用 梯度下降来求 $min_{\theta}J(\theta)$ 。 与回归一样，我们要做的就是不断更新 $\theta$ $\theta := \theta - \alpha \frac{\partial J}{\partial \theta}$ 接下来我们来推导一下 $\frac{\partial J}{\partial \theta}$ 。 首先，我们有 $X_{m \times (n+1)}\begin{bmatrix}x_{0}^{(1)} &amp; x_{1}^{(1)} &amp; \cdots &amp; x_{n}^{(1)}\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ x_{0}^{(m)} &amp; x_{1}^{(m)} &amp; \cdots &amp; x_{n}^{(m)}\end{bmatrix} = \begin{bmatrix}1 &amp; x_{1}^{(1)} &amp; \cdots &amp; x_{n}^{(1)}\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ 1 &amp; x_{1}^{(m)} &amp; \cdots &amp; x_{n}^{(m)}\end{bmatrix}$ $Y_{m\times 1} = \begin{bmatrix} y^{(1)} &amp; \cdots &amp; y^{(m)}\end{bmatrix}^{T}$ $\theta = \begin{bmatrix}\theta_{0} &amp; \theta_{1} &amp; \cdots &amp; \theta_{n} \end{bmatrix}^{T}$ $\frac{\partial J}{\partial \theta} = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)}\frac{\partial log(h_{\theta}(x^{(i)}))}{\partial \theta} + ( 1-y^{(i)})\frac{\partial log(1-h_{\theta}( x^{(i)} ))}{\partial \theta} \right]$ $h_{\theta}(x^{(i)}) = g(\theta^{T}x^{(i)}) = \frac{1}{1+e^{-\theta^{T}x^{(i)}}}$ 因为 $y^{(i)} \frac{\partial log(h_{\theta}(x^{(i)}))}{\partial \theta} = \frac{y^{(i)}}{h_{\theta}(x^{(i)})} \cdot \frac{x^{(i)}e^{-\theta^{T}x^{(i)}}}{(1+e^{-\theta^{T}x^{(i)}})^{2}}$ $= y^{(i)}(1+e^{-\theta^{T}x^{(i)}}) \cdot \frac{x^{(i)}e^{-\theta^{T}x^{(i)}}}{(1+e^{-\theta^{T}x^{(i)}})^{2}}$ $= y^{(i)} \frac{x^{(i)}e^{-\theta^{T}x^{(i)}}}{1+e^{-\theta^{T}x^{(i)}}}$ $= y^{(i)} h_{\theta}(x^{(i)})x^{(i)}e^{-\theta^{T}x^{(i)}}$ 又因为 $(1-y^{(i)}) \frac{\partial log(1-h_{\theta}( x^{(i)} ))}{\partial \theta} = - (1-y^{(i)}) \frac{1}{1-h_{\theta}(x^{(i)})} \cdot \frac{x^{(i)}e^{-\theta^{T}x^{(i)}}}{(1+e^{-\theta^{T}x^{(i)}})^{2}}$ $= - (1-y^{(i)}) \frac{1+e^{-\theta^{T}x^{(i)}}}{e^{-\theta^{T}x^{(i)}}} \cdot \frac{x^{(i)}e^{-\theta^{T}x^{(i)}}}{(1+e^{-\theta^{T}x^{(i)}})^{2}}$ $= - (1-y^{(i)}) \frac{x^{(i)}}{1+e^{-\theta^{T}x^{(i)}}}$ $= - (1-y^{(i)})x^{(i)}h_{\theta}(x^{(i)})$ 将上面两式相加，提出 $h_{\theta}(x^{(i)})x^{(i)}$ ，得 $h_{\theta}(x^{(i)})x^{(i)} \left[y^{(i)}(1+e^{-\theta^{T}x^{(i)}}) - 1\right]$ $= x^{(i)}y^{(i)} - x^{(i)}h_{\theta}(x^{(i)})$ $= x^{(i)} (y^{(i)} - h_{\theta}(x^{(i)}))$ 将上式代入 $\frac{\partial J}{\partial \theta}$ ，则 $\frac{\partial J}{\partial \theta} = \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})x^{(i)}$ 我们惊奇地发现， $\frac{\partial J}{\partial \theta}$ 的表达式居然跟回归是一样的！这就是数学的魅力！ 因此，参考 week1的推导，可得 $\frac{\partial J}{\partial \theta} = \frac{1}{m} X^{T}(X\theta - Y)$ $$\theta := \theta - \alpha \frac{1}{m} X^{T}(X\theta - Y)$$ Multi-class classification: One-vs-all - 多分类问题：一对多 在实际分类问题中，我们遇到的大多是需要 分多个类的问题，比如联系人的分类有家人，朋友，同事，同学等等。在可视化图像中，它们可能会呈现出如下的分布 一对多的做法就是我们分别对这三个类训练 $h_{\theta}^{(i)}(x)$ ，其中 $i$ 为类别序号。如下图所示 训练完所有的 $h_{\theta}^{(i)}(x)$ 后，当我们给一组输入特征 $x$ 时，取 最大的 $h_{\theta}^{(i)}(x)$ 作为我们的预测结果。 Regularization - 正则化 The problem of overfitting - 过拟合问题 假如我们样本有非常多的特征，我们也许能训练出一个在样本集上表现得很好的假设函数 $h_{\theta}(x)$ ，但是对于新的输入，我们可能不能很好地进行拟合（预测）。这类问题，我们称之为 过拟合。 对于过拟合问题我们一般有下面一些解决方法 减少特征数量 手动剔除一些不必要的特征，或者用一些降维算法（PCA）来自动减少特征数 正则化 保留所有的特征，同时减小参数 $\theta$ 的大小 Cost function - 代价函数 首先看下面这两种预测函数在样本集上的结果 我们能看到，左边是比较合适的预测函数，而右边则明显过拟合了。 这时我们用一个小小的技巧，在我们的误差函数 $J(\theta)$ 后面对 $\theta_{3}$ 和 $\theta_{4}$ 加一个 惩罚系数（或者说补偿反馈），使之变为 $J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2} + 1000\theta_{3} + 1000\theta_{4}$ 由上可知，我们要求最优的 $\theta$ ，使得 $J(\theta)$ 取得最小值，那么我们在优化过程中（比如梯度下降） $\theta_{3}$ 和 $\theta_{4}$ 一定 $\rightarrow 0$ ，因为他们占比很大。这样 $\theta_{3}$ 和 $\theta_{4}$ 对 $h_{\theta}(x)$ 的贡献就非常小， $x^{3}$ 和 $x^{4}$ 这些高次项在 $h_{\theta}(x)$ 所占的权重就小很多，有效地防止了 过拟合。 假如我们有非常多的特征，不知道要对哪些对应的参数 $\theta$ 作惩罚，那么最好的办法就是对所有的 $\theta$ 作惩罚，然后让程序自己迭代优化。所以我们的代价函数 $J(\theta)$ 就变成下面这种形式 $J(\theta) = \frac{1}{2m} \left[ \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^{2} + \lambda \sum_{j=1}^{n} \theta_{j}^{2} \right]$ 其中 $\lambda$ 称为 正则化参数。一般我们不对 $\theta_{0}$ 进行惩罚。 正则化后的假设函数如下图所示 其中 蓝色曲线是过拟合的情况， 紫色曲线是正则化后的假设函数曲线，而 橙色直线则是 正则化参数过大 导致的 欠拟合。为什么会这样呢？因为正则化参数过大，会对 $(\theta_{1} \cdots \theta_{n})$ 惩罚过重，以至于 $(\theta_{1} \cdots \theta_{n}) \rightarrow 0$ ，使得 $h_{\theta}(x) \approx \theta_{0}$ 。 因此对于正则化，我们要选一个合适的值，才有好的效果。 Regularized linear regression - 正则化后的线性回归 正则化后我们的代价函数变成 $J(\theta) = \frac{1}{2m} \left\{ \left[\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^{2} \right] + \lambda \sum_{j=1}^{n} \theta_{j}^{2} \right\}$ 如果我们用梯度下降来求最优 $\theta$ ，我们更新 $\theta$ 就要分别更新 $\theta_{0}$ 和 $\theta_{1} \cdots \theta_{n}$ $$\begin{cases} \theta_{0} := \theta_{0} - \alpha \frac{1}{m} \sum_{i=1}^{m}( h_{\theta}(x^{(i)})-y^{(i)} )x_{0}^{(i)} \\ \theta_{j} := \theta_{j} - \alpha \left\{ \frac{1}{m} \left[\sum_{i=1}^{m}( h_{\theta}(x^{(i)})-y^{(i)} )x_{j}^{(i)} \right]+\frac{\lambda}{m}\theta_{j}\right\} &amp; j=1,2, \cdots ,n \end{cases}$$ 其中 $\theta_{j}$ 可以化简成 $\theta_{j}(1-\alpha\frac{\lambda}{m}) - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}$ 我们看到， $(1-\alpha\frac{\lambda}{m}) &lt; 1$ ，所以正则化后的梯度下降实际上就是让 $\theta_{j}$ 减少一定的比例后再进行原来的梯度下降。 我们知道，梯度 $\frac{\partial J}{\partial \theta}$ 为 $0$ 时， $J(\theta)$ 取得极小值，所以我们令 $$\begin{cases} \sum_{i=1}^{m}( h_{\theta}(x^{(i)})-y^{(i)} )x_{0}^{(i)} = 0\\ \sum_{i=1}^{m}( h_{\theta}(x^{(i)})-y^{(i)} )x_{j}^{(i)} + \lambda\theta_{j} = 0 &amp; j=1,2, \cdots ,n \end{cases}$$ 即 $\frac{\partial J}{\partial \theta} =\begin{bmatrix}x_{0}^{(1)} &amp; x_{0}^{(2)} &amp;\cdots &amp; x_{0}^{(m)}\\ x_{1}^{(1)} &amp; x_{1}^{(2)} &amp; \cdots &amp; x_{1}^{(m)}\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{n}^{(1)} &amp; x_{n}^{(2)} &amp; \cdots &amp; x_{n}^{(m)}\end{bmatrix} \begin{bmatrix}h_{\theta}(x^{(1)})-y^{(1)}\\h_{\theta}(x^{(2)})-y^{(2)}\\ \vdots\\h_{\theta}(x^{(m)})-y^{(m)}\end{bmatrix} + \lambda \begin{bmatrix}0\\ \theta_{1}\\ \vdots \\ \theta_{n}\end{bmatrix} = 0$ 也即 $X^{T}(X\theta - Y) + \lambda \begin{bmatrix}0 &amp; &amp; &amp; \\ &amp; 1 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; 1\end{bmatrix}_{(n+1)^{2}} \theta = 0$ 去掉括号，并提出 $\theta$ ，整理等式 $(X^{T}X + \lambda\begin{bmatrix}0 &amp; &amp; &amp; \\ &amp; 1 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; 1\end{bmatrix}_{(n+1)^{2}}) \theta = X^{T}Y$ 最后我们可得 $\theta = (X^{T}X + \lambda\begin{bmatrix}0 &amp; &amp; &amp; \\ &amp; 1 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; 1\end{bmatrix}_{(n+1)^{2}})^{-1} X^{T}Y$ 上式就是正则化后的 Normal equation - 正规方程，其中 $(X^{T}X + \lambda\begin{bmatrix}0 &amp; &amp; &amp; \\ &amp; 1 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; 1\end{bmatrix}_{(n+1)^{2}})$ 一定是可逆的。这个就不在此作证明了。 Regularized logistic regression - 正则化后的逻辑斯谛回归 与线性回归一样，我们在原来的代价函数 $J(\theta)$ 后面加上一个惩罚项，则 $J(\theta)$ 变成 $J(\theta) = - \left\{ \frac{1}{m} \sum_{i=1}^{m} \left[ y^{\left( i \right)}log\left( h_{\theta}\left( x^{\left( i \right)} \right) \right) + \left( 1-y^{\left( i \right)} \right)log\left( 1-h_{\theta}\left( x^{\left( i \right)} \right) \right) \right] \right\} + \frac{\lambda}{2m} \sum_{j=1}^{2} \theta_{j}^{2}$ 因为其 $\frac{\partial J(\theta)}{\partial \theta}$ 的形式与上面线性回归一样，所以梯度下降的过程同上。 课程资料 week3课程讲义 编程作业ex2]]></content>
      <categories>
        <category>机器学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (Week2)]]></title>
    <url>%2Fposts%2FMachine%20Learning%20(Week2)%2F</url>
    <content type="text"><![CDATA[在第二周的课程里，主要讲了 多变量线性回归以及相应的 梯度下降实践，一些梯度下降的技巧如 学习速率的选择， Feature Scaling - 特征缩放等，最后介绍了 Polynomial Regression - 多项式回归和 Normal Equation - 正规方程。 Linear Regression with multiple variables - 多变量线性回归 Multiple Feature - 多变量 参考 week1 第二节内容。 Gradient Descent for multiple variable - 多变量梯度下降 参考 week1 第三节内容。 Gradient Descent in practise 1: Feature Scaling - 梯度下降实践1：特征缩放 首先还是用房价预测回归的例子来说明： 假设我们有两个特征： $x_{1} = size(feet_{2}) \in (0,2000)$ $x_{2} = number of bedrooms \in (1,5)$ 可以看到 $x_{1}$ 比 $x_{2}$ 的取值范围要大了几个数量级。这么做的直接后果就是，只要 $x_{1}$ 的参数 $\theta_{1}$ 稍微变化一下，预测值 $h_{\theta}(x)$ 与实际价格之间的误差就会偏移得很厉害，也就导致 $J(\theta)$ 在 $\theta_{1}$ 偏移得很厉害，如下图所示： 我们看到，假如对此进行梯度下降，须迭代多次才能达到极值点。显然这是不ok的。 所以我们要对 $x_{1}$ 和 $x_{2}$ 进行缩放，让他们的取值范围落在同一个区间，或者相近区间。 一般我们会用下面的方法进行缩放： $x_{1} = \frac{size(feet_{2})}{2000}$ $x_{2} = \frac{number of bedrooms}{5}$ 这样我们就能令 $x_{1},x_{2} \in [0,1]$ ，这种方法也叫 归一化。 我们在做梯度下降时，速度就会快很多： 更普遍的，我们采用如下方法： $x := \frac{x-\mu}{s}$ 其中$\mu$为$x$的均值，$s$为$x$的方差。这样就能令$x\in (-1,1)$。 Gradient Descent in practise 2: Learning rate - 梯度下降实践2：学习速率 如何选择学习速率是做梯度下降的很关键的一步。在 week1 第三节的内容里，我们了解到学习速率$\alpha$设置不当会有怎样的结果。所以当我们做梯度下降时一定要确保每一次迭代时$J(\theta)$都在 减小，最后收敛于某个值。一般我们可以作 迭代次数 - $J(\theta)$图来观察$J(\theta)$是否收敛： 收敛 发散 或者设置某个阈值（比如$0.001$）来检测， 当$J(\theta)$ 减小的差值小于阈值时，可以认为$J(\theta)$已收敛到极值。 Features and Polynomial Regression - 特征与多项式回归 线性回归顾名思义，用于特征与结果有明显的线性关系时的情况。假如我们的某些特征与结果是非线性关系的，比如下图，我们只要观察散点的分布趋向哪种多项式函数然后做拟合就好了： Normal Equation - 正规方程 根据 week1 第三节最后的内容，我们得到： $$\frac{\partial J}{\partial \theta} = grad_{(n+1)\times 1} = \frac{1}{m} X^{T}(X\theta - Y)$$ 令其为$0$，可得： $$X^{T}X\theta - X^{T}Y = 0$$ $X^{T}X\theta = X^{T}Y$ 则得： $\theta = (X^{T}X)^{-1}X^{T}Y$ 其中要注意的是，$X^{T}X$不一定是可逆的。比如 特征数过多$(m&lt;&lt;n)$，此时$r(X)\leq m$，$r(X^{T}X)\leq min(r(X),r(X^{T}))\leq m &lt; n$。而$X^{T}X\in n\times n$，因此$X^{T}X$是不可逆的。 因此在 样本数量远大于特征数量时才能用正规方程。 小结 具体问题具体分析，梯度下降虽然基础，但在许多问题上仍然是很有效的。正规方程用在合适的问题上则能非常快的得出结果。各司其职。 课程资料 week2课程讲义 编程作业ex1]]></content>
      <categories>
        <category>机器学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning.ai 1 - Neural Networks and Deep Learning (week1)]]></title>
    <url>%2Fposts%2Fdeeplearning.ai%201%20-%20Neural%20Networks%20and%20Deep%20Learning%20(week1)%2F</url>
    <content type="text"><![CDATA[第一周的课程里主要是简单介绍 deeplearning - 深度学习， Neural NetWork - 神经网络的概念。 Introduction to Deep Learning - 深度学习简介 What is Neural Network? - 什么是神经网络？ 其实 神经网络并没有想象中那么复杂，它由三部分组成： 输入层 隐藏层 输出层 其中每一层都包含数个 neuron - 神经元，我称之为 计算节点。每一层的每一个节点都完成一种计算任务，上一层的节点计算的结果会作为当前层的节点的输入，当前层节点的输出则作为下一层节点的输入。 我们用一个简单的例子来解释： 假如现在有一组数据，是关于房子面积和价格的表格，如下： $Size in feet^{2}$ (x) $prize$ (y) 2104 460 1416 232 1534 315 852 178 我们可以作线性回归，可能画出来的图是这样的： 那么我们可以作如下定义： 输入层节点为房子面积$(x)$ 隐藏层节点为 蓝色直线所代表的 拟合函数 $(f)$ 输出层节点为 拟合函数在对应输入上的输出$(\hat{y})$ 可作下图： graph LR; x((x)) --> f((f)); f((f)) --> y((yhat)); 这就是最简单的神经网络，它只有$3$层，每层只有$1$个节点。只要我们将随便一个房屋子的面积作为输入丢进去，它就会帮我们预测输出价格。 可是只靠面积来预测价格肯定是不严谨的，可能会有多个因素，比如地段，交通便利情况等。这时我们就会有多个输入，也就意味着输入层节点有多个，与输入的特征一一对应。 我的总结， 神经网络就是一个多层的嵌套函数。这句话会在后面的笔记得以充分体现。 Supervised Learning with Neural Networks - 有监督学习神经网络 有监督学习，简要的说，就是我们有一个 数据集，并且我们知道这对数据的 输出是张什么样的，而且可以肯定作为变量的输入数据与作为结果的输出数据之间有着必然的联系。 有监督学习通常分为 regression - 回归与 classification - 分类两类问题。 对于回归问题，一般我们的数据都是 Structured - 结构化 的，有着明显的特征： 对于分类问题，数据一般是 Unstructured - 无结构化的，特征不明显： 关于神经网络的发展请阅读课程资料，这里不在赘述。 课程资料 week1课程讲义]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
        <tag>深度学习</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning.ai 0 (openning)]]></title>
    <url>%2Fposts%2Fdeeplearning.ai%200%20(openning)%2F</url>
    <content type="text"><![CDATA[开篇的话 大约上个月，在 Coursera上申请 Andrew Ng的 deeplearning.ai系列课程助学金通过了。想着偏偏在我复习考研的时间段里开课，又不想转换班次，于是“狠下心来”开始上课，这下负担又重了，不仅要复习，还要兼顾Coursera上两门重量级课程，虽然有做笔记和推导，但是实在没有时间再去做整理发布了。 那么为什么会有这个开篇呢？因为我实在忍不住。今天刚上完 系列课程1–Neural Networks and Deep Learning的 week3课程，而 Machine Learning那边也进行到 week6。因为在 Machine Learning里也教到 Back Propagation - 反向传播算法后面一点的内容，同样的 deeplearning那边也讲到，感觉对 BP有了非常清晰的思路。迫不及待想整理上来。趁着国庆做一次详细整理吧。 以下是一些关于此课程笔记的事项： 这里记录了我在Coursera上学习deeplearning.ai专项课程的笔记 同时会把课程相关资料整理一并发布，包括视频，lecturenote，homework，和我的答案解释。 课程链接:可以申请助学金以免费听课，需15个工作日处理。]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
        <tag>深度学习</tag>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (Week1)]]></title>
    <url>%2Fposts%2FMachine%20Learning%20(Week1)%2F</url>
    <content type="text"><![CDATA[在第一周的课程里简要介绍了 什么是机器学习， Model - 模型和 Cost Function - 代价函数的概念，以及一些必要的 线性代数的知识。 特别声明：这里不会对线性代数基础进行记录，有需要了解的请自行学习。 敬请留意 Introduction - 简介 What is Machine Learning? - 何为机器学习？ 引用Tom Mitchell的经典解释（有点像绕口令） Two definitions of Machine Learning are offered. Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition. Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” Example: playing checkers. E = the experience of playing many games of checkers T = the task of playing checkers. P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning and Unsupervised learning. Supervised Learning - 有监督学习 有监督学习，简要的说，就是我们有一个 数据集，并且我们知道这对数据的 输出是张什么样的，而且可以肯定作为变量的输入数据与作为结果的输出数据之间有着必然的联系。 有监督学习通常分为 regression - 回归与 classification - 分类两类问题。 在回归问题中，我们要做的就是得到一个连续的 预测函数去拟合离散的数据，也就是要把 输入变量映射到连续函数上，从而实现未知数据的预测。 例子： Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. We could turn this example into a classification problem by instead making our output about whether the house “sells for more or less than the asking price.” Here we are classifying the houses based on price into two discrete categories. 在分类问题中，输出结果是离散的，比如二分类问题，每一类别分别对应0,1两个离散数值，我们要做的就是得到一个 预测函数，能够根据输入变量得到离散的输出结果，也就是要把 输入变量映射到离散的类别中 例子： (a) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign. (b) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture Unsupervised Learning - 无监督学习 无监督学习就是有监督学习的反面情况，即我们有一组数据集，但我们并不知道它的输出结果是什么，或者它根本就没有输出，甚至它本身代表什么我们都不知道。我们要做的就是从这堆数据中 找出它的规律或者结构，来确定这些输入变量产生的影响，比如将这堆数据分组。 特别的是，无监督学习并不像有监督学习那样有基于预测结果的反馈。 现实生活中有很多这样的例子，比如你有一堆新闻内容的数据，你要把有关联的分成一组。像这样的算法叫做 聚类，就如字面意思一样。 例子： Model and Cost Function - 模型与代价函数 Model Representation - 模型的表示方法 对于 有监督学习，在这门课程里有一套专门的符号，参数，公式的表示方法： $vector$: 向量（都指列向量） $m$: 训练样本组数 $x^{\left(i \right)}$ : 第$i$组输入变量（一般为向量） $y^{\left(i \right)}$: 第$i$组输出变量（一般为向量） $\left(x^{\left(i \right)}, y^{\left(i \right)} \right)$: 第$i$组训练样本 $\left(x, y\right)$: 全体训练样本数据 $X$: 输入变量空间（一般为矩阵） $Y$: 输出变量空间（一般为矩阵） $h_{\theta} \left(x \right)$: 预测函数 $\theta_{j}$: 第$j$组学习参数 例子： 假设我们有一组（房子面积, 价格）数据集，对应下表: $Size in feet^{2}$ (x) $prize$ (y) 2104 460 1416 232 1534 315 852 178 其中 $m = 4$ $x^{\left(1 \right)} = 2104$ $y^{\left(1 \right)} = 460$ $\left(x^{\left(1 \right)}, y^{\left(1 \right)} \right) = (2104, 460)$ $X$ = $\begin{bmatrix}2104 &amp; 1416 &amp; 1534 &amp; 852\end{bmatrix}^{T}$ $Y$ = $\begin{bmatrix}460 &amp; 232 &amp; 315 &amp; 178\end{bmatrix}^{T}$ $h_{\theta}\left(x\right)=\theta_{0}+\theta_{1}x$ $\theta_{1}$: 第$1$组学习参数 对于多变量（或者叫 feature - 特征）的表示方法，如下 例子： 假设我们有一组多个特征的数据，每组特征对应一个确定的输出： $X_{0}$ $X_{1}$ $X_{2}$ $X_{3}$ … $X_{n}$ $Y$ $1$ $x_{1}^{(1)}$ $x_{2}^{(1)}$ $x_{3}^{(1)}$ … $x_{n}^{(1)}$ $y^{(1)}$ $1$ $x_{1}^{(2)}$ $x_{2}^{(2)}$ $x_{3}^{(2)}$ … $x_{n}^{(2)}$ $y^{(2)}$ $1$ $x_{1}^{(3)}$ $x_{2}^{(3)}$ $x_{3}^{(3)}$ … $x_{n}^{(3)}$ $y^{(3)}$ … … … … … … … $1$ $x_{1}^{(m)}$ $x_{2}^{(m)}$ $x_{3}^{(m)}$ … $x_{n}^{(m)}$ $y^{(m)}$ 其中 $X_{m\times (n+1)} = \begin{bmatrix}1 &amp; x_{1}^{(1)} &amp; \cdots &amp;x_{n}^{(1)} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_{1}^{(m)} &amp; \cdots &amp; x_{n}^{(m)} \\ \end{bmatrix}$ $Y_{m\times 1} = \begin{bmatrix} y^{(1)} &amp; \cdots &amp; y^{(m)}\end{bmatrix}^{T}$ $\theta = \begin{bmatrix} \theta_{0} &amp; \theta_{1} &amp; \cdots &amp; \theta_{n} \end{bmatrix}^{T}$ $h_{\theta}\left(x\right)=\begin{bmatrix}h_{\theta}\left(x^{(1)}\right)&amp;h_{\theta}\left(x^{(2)}\right)&amp;\cdots&amp;h_{\theta}\left(x^{(m)}\right)\end{bmatrix}^{T}=\begin{bmatrix}\theta^{T}x^{(1)}&amp;\theta^{T}x^{(2)}&amp;\cdots&amp;\theta^{T}x^{(m)}\end{bmatrix}^{T}$ 整个监督学习的过程，就是找到最优的$\theta$，从而得到最优的 $h_{\theta}\left(x\right)$ 。对于 回归问题，预测就是我们把一组$x$丢进 $h_{\theta}\left(x\right)$ 中，得到的结果就是预测值。对于 分类问题，$h_{\theta}\left(x\right)$得到的结果是一个概率，即输入$x$属于某一类的概率值是多少。或许你觉得我解释得很抽象，因为这里的内容只是让你的大脑对机器学习有一个大致的轮廓。详细的过程将记录在后面的笔记中，请读者放心。 Cost Function - 代价函数 回到我们上面的那个（房子面积, 价格）数据集的例子中。这是一个 单变量的回归问题。如下 在这里，我们的预测函数为 $h_{\theta}(x)=\theta_{0}+\theta_{1}x$ 。当$\theta$取不同值时，对应如下图： 我们要找到最优的$\theta$去拟合$(x,y)$，首先就要定义一个能判断当前$\theta$是否最优的函数，这个函数就是 代价函数。在这里我们将它定义为$J(\theta)$。 那么它等于什么呢？下面给个直观的图例辅助解释： 在这幅图里，有3组样本数据为 $X$ $Y$ 1 1 2 2 3 3 分别对应上图三个 红色×点。 黑色斜线为 $h_{\theta}(x)=0+0.5x$ 过这3点分别作垂直于$x$轴的 垂线段交于 $h_{\theta}(x)$ 。则第$i$个样本点的误差（即代价）就是该样本点对应 垂线段的长度，为 $\left|h_{\theta}(x^{(i)})-y^{(i)}\right|$ 为方便处理，我们将绝对值去掉，重新定义误差为 $\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 则总误差为 $\sum_{i=1}^{3}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 平均误差为 $\frac{1}{3}\sum_{i=1}^{3}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 为了方便后面处理，这里我们一般将平均误差乘一个$\frac{1}{2}$，即 $\frac{1}{2 \times 3}\sum_{i=1}^{3}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 上式就是我们的代价函数，即 $J(\theta)=\frac{1}{6}\sum_{i=1}^{3}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 将上式扩展到$m$个样本点的一般情况，即 $J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 当我们的$\theta$能令$J(\theta)$取到最小值时，我们就认为这是最优的$\theta$。 是不是很直观？ 有了代价函数之后，我们要做的就是找出令它取得最小值的$\theta$，下图就是我们的任务： Parameter Learning - 参数学习 Gradient Descent - 梯度下降 这是典型的极值问题，在数学方法中，我们可以求导解决，可是在计算机程序中，我们要用一种 通用的数值方法，去逼近。 我们看只有一个学习参数的情况，假设 $h_{\theta}(x)=\theta x$ 当 $\theta$ 比较小时： 我们看到 $h_{\theta}(x)$ 没有很好地拟合数据， $J(\theta)$ 比较大。 当 $\theta$ 比较大时： 同样的， $h_{\theta}(x)$ 没有很好地拟合数据， $J(\theta)$ 比较大。 当 $\theta$ 比取到能使 $h_{\theta}(x)=\theta x$ 很好地拟合数据时： 这时的 $\theta$ 就是 $J(\theta)$ 的极小值点。也就是最优的 $\theta$ 。 接下来我们就来讲，如何让计算机自动训练出最优的$\theta$ 我们继续用上面的例子， 当 $\theta$ 比较小时： 我们求得 $J(\theta)$ 在当前 $\theta$ 的导数， 小于 $0$ 。此时我们把 $\theta$ 更新为 $\theta - \alpha\frac{dJ(\theta)}{d\theta}$ ， $\theta$ 就会 变大，往极值点靠近。其中 $\alpha$ 为 学习速率。 当 $\theta$ 比较大时： 我们求得 $J(\theta)$ 在当前 $\theta$ 的导数， 大于 $0$ 。此时我们把 $\theta$ 更新为 $\theta - \alpha\frac{dJ(\theta)}{d\theta}$ ， $\theta$ 就会 减小，往极值点靠近。其中 $\alpha$ 为 学习速率。 这就是 梯度下降算法。通过多次的迭代，更新 $\theta$ ，我们就能无限逼近最优值。 将 $\theta$ 拓展到 二维向量（即有两个参数）的情形，我们可能会得到如下的 $J(\theta)$ ： 这是一个二维曲面，这种情况我们就要分别对 $\theta_{0},\theta_{1}$ 求偏导来进行梯度下降。 对于梯度下降，还有一些要注意的地方： 关于 学习速率 $\alpha$ ，怎样设置学习速率也是很关键的问题，如果 $\alpha$ 设置的 过小，则梯度下降就会收敛得很慢，训练时间会过长。如果 $\alpha$ 设置的过大，则梯度下降有可能会发散，就是越过了极值点： 所以我们在做迭代时一定要关注着$J(\theta)$，确保它是在下降的。 在实际问题中，我们的 $J(\theta)$ 一般不会是 凸函数，也就是说我们做梯度下降得到的只是 局部最优值，而不是 全局最优值： Gradient Descent for Liner Regression - 线性回归中的梯度下降 对于线性回归，我们有如下定义： $X_{m\times (n+1)} = \begin{bmatrix}1 &amp; x_{1}^{(1)} &amp; \cdots &amp;x_{n}^{(1)} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_{1}^{(m)} &amp; \cdots &amp; x_{n}^{(m)} \\ \end{bmatrix}$ $Y_{m\times 1} = \begin{bmatrix} y^{(1)} &amp; \cdots &amp; y^{(m)}\end{bmatrix}^{T}$ $\theta = \begin{bmatrix} \theta_{0} &amp; \theta_{1} &amp; \cdots &amp; \theta_{n} \end{bmatrix}^{T}$ $h_{\theta}\left(x\right)=\begin{bmatrix}h_{\theta}\left(x^{(1)}\right)&amp;h_{\theta}\left(x^{(2)}\right)&amp;\cdots&amp;h_{\theta}\left(x^{(m)}\right)\end{bmatrix}^{T}=\begin{bmatrix}\theta^{T}x^{(1)}&amp;\theta^{T}x^{(2)}&amp;\cdots&amp;\theta^{T}x^{(m)}\end{bmatrix}^{T} = X \theta$ $h_{\theta}\left(x^{(i)}\right) = \theta_{0} + \theta_{1}x_{1}^{(i)} + \cdots + \theta_{n}x_{n}^{(i)}$ $J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^{2}$ 我们对 $J(\theta)$ 求所有 $\theta$ 的偏导： $\frac{\partial J}{\partial \theta_{j}} = \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{i} \right) \frac{\partial h_{\theta}(x^{(i)})}{\partial \theta_{j}} \right]$ 当 $j=0$ 时： $\frac{\partial h_{\theta}(x^{(i)})}{\partial \theta_{0}} = 1$ 当 $j=1 \cdots n$ 时： $\frac{\partial h_{\theta}(x^{(i)})}{\partial \theta_{j}} = x_{j}^{(i)}$ 综上： $\frac{\partial J}{\partial \theta_{0}} = \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{(i)} \right)\right]$ $\frac{\partial J}{\partial \theta_{1}} = \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{(i)} \right) x_{1}^{(i)} \right]$ $\vdots$ $\frac{\partial J}{\partial \theta_{n}} = \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{(i)} \right) x_{n}^{(i)} \right]$ 更新 $\theta$ ： $\theta_{0}:=\theta_{0} - \alpha \frac{\partial J}{\partial \theta_{0}} = \theta_{0} - \alpha \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{(i)} \right)\right]$ $\theta_{1}:=\theta_{1} - \alpha \frac{\partial J}{\partial \theta_{1}} = \theta_{1} - \alpha \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{(i)} \right) x_{1}^{(i)} \right]$ $\vdots$ $\theta_{n}:=\theta_{n} - \alpha \frac{\partial J}{\partial \theta_{n}} = \theta_{n} - \alpha \frac{1}{m} \sum_{i=1}^{m} \left[\left( h_{\theta}(x^{(i)})-y^{(i)} \right) x_{n}^{(i)} \right]$ 我们将上述过程向量化： 首先将偏导数向量化： $$\frac{\partial J}{\partial \theta_{0}} = \frac{1}{m} \begin{bmatrix}1&amp;1&amp;\cdots&amp;1\end{bmatrix} \begin{bmatrix}h_{\theta}(x^{(1)})-y^{(1)}\\h_{\theta}(x^{(2)})-y^{(2)}\\ \vdots\\h_{\theta}(x^{(m)})-y^{(m)}\end{bmatrix}$$ $$\frac{\partial J}{\partial \theta_{1}} = \frac{1}{m} \begin{bmatrix}x_{1}^{(1)}&amp;x_{1}^{(2)}&amp;\cdots&amp;x_{1}^{(m)}\end{bmatrix} \begin{bmatrix}h_{\theta}(x^{(1)})-y^{(1)}\\h_{\theta}(x^{(2)})-y^{(2)}\\ \vdots\\h_{\theta}(x^{(m)})-y^{(m)}\end{bmatrix}$$ $$\vdots$$ $$\frac{\partial J}{\partial \theta_{n}} = \frac{1}{m} \begin{bmatrix}x_{n}^{(1)}&amp;x_{n}^{(2)}&amp;\cdots&amp;x_{n}^{(m)}\end{bmatrix} \begin{bmatrix}h_{\theta}(x^{(1)})-y^{(1)}\\h_{\theta}(x^{(2)})-y^{(2)}\\ \vdots\\h_{\theta}(x^{(m)})-y^{(m)}\end{bmatrix}$$ 可得： $$\frac{\partial J}{\partial \theta} = grad_{(n+1)\times 1} = \begin{bmatrix}\frac{\partial J}{\partial \theta_{0}}\\\frac{\partial J}{\partial \theta_{1}}\\ \vdots\\\frac{\partial J}{\partial \theta_{n}}\end{bmatrix} = \frac{1}{m} X^{T}(X\theta - Y)$$ 接着将梯度下降的过程向量化： $$\theta := \theta - \alpha \frac{1}{m} X^{T}(X\theta - Y)$$ PS:其实上面的 多变量线性回归梯度下降 是 week2的内容，因为不算太复杂我就搬到这里讲了，那么 week2的笔记里就会跳过这部分内容，请大家注意。 课程资料 week1课程讲义]]></content>
      <categories>
        <category>机器学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (Week0) Openning]]></title>
    <url>%2Fposts%2FMachine%20Learning%20(Week0)%20Openning%2F</url>
    <content type="text"><![CDATA[开篇的话 这里记录了我在Coursera上听吴恩达机器学习课程的笔记，以表示我是有学习的:) 同时会把课程相关资料整理一并发布，包括lecturenote，homework，和我的答案解释。 课程链接:可以直接注册听课，但是不会有证书。 特别声明：笔记在一些对类似什么是机器学习，机器学习的应用这些字面意义上的概念只会一笔带过，需要了解的自行谷歌或百度，笔记之着重于机器学习本身的内容，算法，推导，在一些理论细节上可能会做详细深入。 敬请留意]]></content>
      <categories>
        <category>机器学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[发布测试]]></title>
    <url>%2Fposts%2F%E5%8F%91%E5%B8%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[博客发布测试 2级标题 123 from bs4 import BeautifulSoupdef func(args): return args Content (md partial supported) Content (md partial supported) Content (md partial supported) Content (md partial supported) Content (md partial supported) Content (md partial supported) Content (md partial supported) &nbsp;未完待续…有空继续… $$n\cdot m\cdot \lg b$$ Simple inline $a = b + c$. $$\frac{\partial u}{\partial t} = h^2 \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} + \frac{\partial^2 u}{\partial z^2}\right)$$ $$J\left(\theta\right) = -\left[\frac{1}{m}\sum_{i=1}^{m}y^\left(i\right)log\left(h_{\theta}\left(x^{\left(i\right)}\right)\right)+ \left(1-y^{\left(i\right)}\right)log\left(1-h_{\theta}\left(x^{\left(i\right)}\right)\right)\right]+ \frac{\lambda}{2m}\sum_{j=1}^{n}\theta_{j}^{2}$$ $Size in feet^{2}$ (x) $prize$ (y) 2104 460 1416 232 1534 315 852 178 graph LR; a11(("a1[0](i)")) --> a12(("a1[1](i)")); a11(("a1[0](i)")) --> a22(("a2[1](i)")); a11(("a1[0](i)")) --> a32(("a3[1](i)")); a21(("a2[0](i)")) --> a12(("a1[1](i)")); a21(("a2[0](i)")) --> a22(("a2[1](i)")); a21(("a2[0](i)")) --> a32(("a3[1](i)")); a31(("a3[0](i)")) --> a12(("a1[1](i)")); a31(("a3[0](i)")) --> a22(("a2[1](i)")); a31(("a3[0](i)")) --> a32(("a3[1](i)")); a12(("a1[1](i)")) --> y(("a1[2](i)")); a22(("a2[1](i)")) --> y(("a1[2](i)")); a32(("a3[1](i)")) --> y(("a1[2](i)")); y(("a1[2](i)")) --> yh((yhat)); graph TB; subgraph L0; a11(("a1[0](i)")) --- a21(("a2[0](i)")); a21(("a2[0](i)")) --- a31(("a3[0](i)")); end;]]></content>
      <categories>
        <category>回收站</category>
      </categories>
      <tags>
        <tag>博客测试</tag>
      </tags>
  </entry>
</search>
